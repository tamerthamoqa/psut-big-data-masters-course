{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stjZ7fFzVRDY"
   },
   "source": [
    "<center><img src=\"https://drive.google.com/uc?export=view&id=1f0tvL6DLzfOQ_xHNdaBe_6fDUd27lc6U\" alt=\"PSUT\"  width=\"180px\"> \n",
    "<p> \n",
    "King Hussein School for Computing Sciences <br>\n",
    "Department of Data Science <br>\n",
    "\n",
    "<b>Big Data 2020-2021 </b> \n",
    "</p></center>\n",
    "\n",
    "\n",
    "<hr>\n",
    "<h4><b>Grading </b></h4>\n",
    "\n",
    "<table border>\n",
    "<tr>\n",
    "<td> <b>Question</b></td>\n",
    "<td> <b>Mark</b></td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td> <b>Q1</b></td>\n",
    "<td>  /2</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td> <b>Q2</b></td>\n",
    "<td>  /2</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td> <b>Q3</b></td>\n",
    "<td>  /2</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td> <b>Q4</b></td>\n",
    "<td>  /4</td>\n",
    "</tr>\n",
    "\n",
    "<td> <b>Total</b></td>\n",
    "<th colspan=3> /10</th> \n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "<h4><b>Programming Assignment Guidelines</b></h4>\n",
    "<ul>\n",
    "\n",
    "\n",
    "<li>  The assignment should be performed individually.\n",
    "<li>  Cutoff date for this homeworkis 19/01/2021 @ 23:59\n",
    "<li>  Any late assignment will not be accepted.\n",
    "<li>  Academic Fraud: Cases of plagiarism will be dealt with according to university regulations.\n",
    "<li>  Your homework should be written in ajupyter notebook file\n",
    "<li>  Show all code in each step.\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Name: Tamer Tahamoqa\n",
    "### Student ID: 20208019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-HFlwFaUYoE"
   },
   "source": [
    "\n",
    "# Questions\n",
    "\n",
    "## The Dataset file contains 9 columns (A,B,C,.., H, Class). Note that the data is \";\" seperated file. Download the dataset file from E-learning System or use this [Link](https://drive.google.com/uc?export=download&id=1r4SnJcvE3x0YMqeiB3uAtevegKO6MbNr) then use Spark to load the dataset as a spark DataFrame. \n",
    "\n",
    "**Q1 *Min-max normalization*:**\n",
    "\n",
    "> Use Spark API to transform all numeric columns using Min-Max scaling approach.Then store all normalized columns except the class column in a separate file (name it NormalizedFile.csv), the file should include 8 columns.\n",
    "\n",
    "**Q2. *Z-score normalization*:**\n",
    "\n",
    "> Use Spark API to transform all numeric columns using z-score approach. Then store all normalized columns except the class column in a separate file (name it ZSCORENormalizedFile.csv), the file should include 8 columns.\n",
    "\n",
    "**Q3. *K-means* on Normalized and Scaled features:**\n",
    "\n",
    "> Use Spark API to to train kmeans clustering model to cluster the dataset file (NormalizedFile.csv) and then the dataset file (ZSCORENormalizedFile.csv) by using k=2 for each model, and display the cluster number for all rows in both cases. Compare the result for clustering ZSCORENormalizedFile.csv and NormalizedFile.csv. Can Identify which model did better and why? \n",
    "\n",
    "\n",
    "**Q4. *KNN* classifier.** \n",
    "\n",
    "\n",
    "> Use Spark API to train a KNN model on 75% of the Dataset and provide accuracy and confusion matrix using 25% of the Dataset. Compare the performance of the classifer based on Normalized and Scaled features in NormalizedFile.csv and ZSCORENormalizedFile.csv\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and Analyzing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"Dataset.csv\", header=True, inferSchema=True, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- A: integer (nullable = true)\n",
      " |-- B: integer (nullable = true)\n",
      " |-- C: integer (nullable = true)\n",
      " |-- D: integer (nullable = true)\n",
      " |-- E: integer (nullable = true)\n",
      " |-- F: double (nullable = true)\n",
      " |-- G: double (nullable = true)\n",
      " |-- H: integer (nullable = true)\n",
      " |-- Class: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+---------------+\n",
      "|summary|                 A|                B|                 C|                 D|                 E|                 F|                 G|                 H|          Class|\n",
      "+-------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+---------------+\n",
      "|  count|               768|              768|               768|               768|               768|               768|               768|               768|            768|\n",
      "|   mean|3.8450520833333335|     120.89453125|       69.10546875|20.536458333333332| 79.79947916666667|31.992578124999977|0.4718763020833327|33.240885416666664|           null|\n",
      "| stddev|  3.36957806269887|31.97261819513622|19.355807170644777|15.952217567727642|115.24400235133803| 7.884160320375441| 0.331328595012775|11.760231540678689|           null|\n",
      "|    min|                 0|                0|                 0|                 0|                 0|               0.0|             0.078|                21|tested_negative|\n",
      "|    25%|                 1|               99|                62|                 0|                 0|              27.3|             0.243|                24|           null|\n",
      "|    50%|                 3|              117|                72|                23|                29|              32.0|             0.371|                29|           null|\n",
      "|    75%|                 6|              140|                80|                32|               127|              36.6|             0.626|                41|           null|\n",
      "|    max|                17|              199|               122|                99|               846|              67.1|              2.42|                81|tested_positive|\n",
      "+-------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+----+-----+---+---------------+\n",
      "|  A|  B|  C|  D|  E|   F|    G|  H|          Class|\n",
      "+---+---+---+---+---+----+-----+---+---------------+\n",
      "|  6|148| 72| 35|  0|33.6|0.627| 50|tested_positive|\n",
      "|  1| 85| 66| 29|  0|26.6|0.351| 31|tested_negative|\n",
      "|  8|183| 64|  0|  0|23.3|0.672| 32|tested_positive|\n",
      "|  1| 89| 66| 23| 94|28.1|0.167| 21|tested_negative|\n",
      "|  0|137| 40| 35|168|43.1|2.288| 33|tested_positive|\n",
      "|  5|116| 74|  0|  0|25.6|0.201| 30|tested_negative|\n",
      "|  3| 78| 50| 32| 88|31.0|0.248| 26|tested_positive|\n",
      "| 10|115|  0|  0|  0|35.3|0.134| 29|tested_negative|\n",
      "|  2|197| 70| 45|543|30.5|0.158| 53|tested_positive|\n",
      "|  8|125| 96|  0|  0| 0.0|0.232| 54|tested_positive|\n",
      "|  4|110| 92|  0|  0|37.6|0.191| 30|tested_negative|\n",
      "| 10|168| 74|  0|  0|38.0|0.537| 34|tested_positive|\n",
      "| 10|139| 80|  0|  0|27.1|1.441| 57|tested_negative|\n",
      "|  1|189| 60| 23|846|30.1|0.398| 59|tested_positive|\n",
      "|  5|166| 72| 19|175|25.8|0.587| 51|tested_positive|\n",
      "|  7|100|  0|  0|  0|30.0|0.484| 32|tested_positive|\n",
      "|  0|118| 84| 47|230|45.8|0.551| 31|tested_positive|\n",
      "|  7|107| 74|  0|  0|29.6|0.254| 31|tested_positive|\n",
      "|  1|103| 30| 38| 83|43.3|0.183| 33|tested_negative|\n",
      "|  1|115| 70| 30| 96|34.6|0.529| 32|tested_positive|\n",
      "+---+---+---+---+---+----+-----+---+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+---+-----+\n",
      "|  A|  B|  C|  D|  E|  F|  G|  H|Class|\n",
      "+---+---+---+---+---+---+---+---+-----+\n",
      "|  0|  0|  0|  0|  0|  0|  0|  0|    0|\n",
      "+---+---+---+---+---+---+---+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Counting number of missing (nan) values in each column, used this blogpost as a reference:\n",
    "#  https://www.datasciencemadesimple.com/count-of-missing-nanna-and-null-values-in-pyspark/\n",
    "\n",
    "df.select([F.count(F.when(F.isnan(col), col)).alias(col) for col in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+---+-----+\n",
      "|  A|  B|  C|  D|  E|  F|  G|  H|Class|\n",
      "+---+---+---+---+---+---+---+---+-----+\n",
      "|  0|  0|  0|  0|  0|  0|  0|  0|    0|\n",
      "+---+---+---+---+---+---+---+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Counting number of null values in each column, used this blogpost as a reference:\n",
    "#  https://www.datasciencemadesimple.com/count-of-missing-nanna-and-null-values-in-pyspark/\n",
    "\n",
    "df.select([F.count(F.when(F.isnull(col), col)).alias(col) for col in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(count)|\n",
      "+----------+\n",
      "|      null|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking number of duplicate rows\n",
    "#  Used this stackoverflow answer: https://stackoverflow.com/a/48554666\n",
    "df.groupBy(df.columns) \\\n",
    "    .count() \\\n",
    "    .where(F.col('count') > 1) \\\n",
    "    .select(F.sum('count')) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahreE2Yqvy0U"
   },
   "source": [
    "### __Q1__. Min-max normalization:\n",
    "Use Spark API to transform all numeric columns using Min-Max scaling approach.Then store all normalized columns except the class column in a separate file (name it NormalizedFile.csv), the file should include 8 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "\n",
    "numerical_columns = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\"]\n",
    "\n",
    "# Relied on this StackOverflow answer on to run MinMaxScaler on multiple columns\n",
    "#  to keep the 8 columns intact: https://stackoverflow.com/a/60281624\n",
    "vector_assemblers = [\n",
    "    VectorAssembler(inputCols=[column], outputCol=column + \"_vector\")\n",
    "    for column in numerical_columns\n",
    "]\n",
    "\n",
    "minmax_scalers = [\n",
    "    MinMaxScaler(inputCol=column + \"_vector\", outputCol=column + \"_scaled\")\n",
    "    for column in numerical_columns\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(stages=vector_assemblers + minmax_scalers)\n",
    "scaler_model = pipeline.fit(df)\n",
    "\n",
    "minmax_scaled_df = scaler_model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [column for column in numerical_columns] + [f'{column}_vector' for column in numerical_columns] + ['Class']\n",
    "minmax_scaled_df = minmax_scaled_df.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- A_scaled: vector (nullable = true)\n",
      " |-- B_scaled: vector (nullable = true)\n",
      " |-- C_scaled: vector (nullable = true)\n",
      " |-- D_scaled: vector (nullable = true)\n",
      " |-- E_scaled: vector (nullable = true)\n",
      " |-- F_scaled: vector (nullable = true)\n",
      " |-- G_scaled: vector (nullable = true)\n",
      " |-- H_scaled: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "minmax_scaled_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---------------------+---------------------+---------------------+---------------------+---------------------+----------------------+---------------------+\n",
      "|A_scaled              |B_scaled             |C_scaled             |D_scaled             |E_scaled             |F_scaled             |G_scaled              |H_scaled             |\n",
      "+----------------------+---------------------+---------------------+---------------------+---------------------+---------------------+----------------------+---------------------+\n",
      "|[0.35294117647058826] |[0.7437185929648241] |[0.5901639344262295] |[0.35353535353535354]|[0.0]                |[0.5007451564828614] |[0.23441502988898377] |[0.48333333333333334]|\n",
      "|[0.058823529411764705]|[0.4271356783919598] |[0.5409836065573771] |[0.29292929292929293]|[0.0]                |[0.3964232488822653] |[0.11656703672075147] |[0.16666666666666666]|\n",
      "|[0.47058823529411764] |[0.9195979899497487] |[0.5245901639344263] |[0.0]                |[0.0]                |[0.34724292101341286]|[0.2536293766011956]  |[0.18333333333333332]|\n",
      "|[0.058823529411764705]|[0.4472361809045226] |[0.5409836065573771] |[0.23232323232323232]|[0.1111111111111111] |[0.41877794336810736]|[0.038001707941929974]|[0.0]                |\n",
      "|[0.0]                 |[0.6884422110552764] |[0.32786885245901637]|[0.35353535353535354]|[0.19858156028368795]|[0.6423248882265277] |[0.9436379163108454]  |[0.2]                |\n",
      "|[0.29411764705882354] |[0.5829145728643216] |[0.6065573770491803] |[0.0]                |[0.0]                |[0.3815201192250373] |[0.052519214346712216]|[0.15]               |\n",
      "|[0.17647058823529413] |[0.39195979899497485]|[0.4098360655737705] |[0.32323232323232326]|[0.10401891252955082]|[0.4619970193740686] |[0.07258753202391117] |[0.08333333333333333]|\n",
      "|[0.5882352941176471]  |[0.5778894472361809] |[0.0]                |[0.0]                |[0.0]                |[0.526080476900149]  |[0.023911187019641334]|[0.13333333333333333]|\n",
      "|[0.11764705882352941] |[0.9899497487437185] |[0.5737704918032787] |[0.45454545454545453]|[0.6418439716312057] |[0.4545454545454546] |[0.034158838599487616]|[0.5333333333333333] |\n",
      "|[0.47058823529411764] |[0.628140703517588]  |[0.7868852459016393] |[0.0]                |[0.0]                |[0.0]                |[0.06575576430401367] |[0.55]               |\n",
      "|[0.23529411764705882] |[0.5527638190954773] |[0.7540983606557377] |[0.0]                |[0.0]                |[0.5603576751117736] |[0.04824935952177626] |[0.15]               |\n",
      "|[0.5882352941176471]  |[0.8442211055276382] |[0.6065573770491803] |[0.0]                |[0.0]                |[0.5663189269746647] |[0.1959863364645602]  |[0.21666666666666667]|\n",
      "|[0.5882352941176471]  |[0.6984924623115578] |[0.6557377049180327] |[0.0]                |[0.0]                |[0.40387481371087935]|[0.5819812126387702]  |[0.6]                |\n",
      "|[0.058823529411764705]|[0.949748743718593]  |[0.4918032786885246] |[0.23232323232323232]|[1.0]                |[0.4485842026825634] |[0.13663535439795046] |[0.6333333333333333] |\n",
      "|[0.29411764705882354] |[0.8341708542713567] |[0.5901639344262295] |[0.1919191919191919] |[0.20685579196217493]|[0.3845007451564829] |[0.21733561058923997] |[0.5]                |\n",
      "|[0.4117647058823529]  |[0.5025125628140703] |[0.0]                |[0.0]                |[0.0]                |[0.44709388971684055]|[0.17335610589239964] |[0.18333333333333332]|\n",
      "|[0.0]                 |[0.592964824120603]  |[0.6885245901639344] |[0.47474747474747475]|[0.2718676122931442] |[0.6825633383010432] |[0.20196413321947054] |[0.16666666666666666]|\n",
      "|[0.4117647058823529]  |[0.5376884422110553] |[0.6065573770491803] |[0.0]                |[0.0]                |[0.4411326378539494] |[0.07514944491887275] |[0.16666666666666666]|\n",
      "|[0.058823529411764705]|[0.5175879396984925] |[0.2459016393442623] |[0.3838383838383838] |[0.09810874704491726]|[0.6453055141579732] |[0.04483347566182749] |[0.2]                |\n",
      "|[0.058823529411764705]|[0.5778894472361809] |[0.5737704918032787] |[0.30303030303030304]|[0.11347517730496454]|[0.5156482861400895] |[0.19257045260461145] |[0.18333333333333332]|\n",
      "+----------------------+---------------------+---------------------+---------------------+---------------------+---------------------+----------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "minmax_scaled_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing column data type from vector to double for pyspark csv write to occur without errors\n",
    "#  https://stackoverflow.com/a/51842141\n",
    "#  https://stackoverflow.com/a/46890719\n",
    "#  https://stackoverflow.com/a/61009640\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "cast_from_vector_to_double = F.udf(lambda x : x.toArray().tolist()[0], DoubleType())\n",
    "\n",
    "for column_name in minmax_scaled_df.columns:\n",
    "    minmax_scaled_df = minmax_scaled_df.withColumn(column_name, cast_from_vector_to_double(column_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+-------------------+-------------------+-------------------+--------------------+-------------------+\n",
      "|            A_scaled|           B_scaled|           C_scaled|           D_scaled|           E_scaled|           F_scaled|            G_scaled|           H_scaled|\n",
      "+--------------------+-------------------+-------------------+-------------------+-------------------+-------------------+--------------------+-------------------+\n",
      "| 0.35294117647058826| 0.7437185929648241| 0.5901639344262295|0.35353535353535354|                0.0| 0.5007451564828614| 0.23441502988898377|0.48333333333333334|\n",
      "|0.058823529411764705| 0.4271356783919598| 0.5409836065573771|0.29292929292929293|                0.0| 0.3964232488822653| 0.11656703672075147|0.16666666666666666|\n",
      "| 0.47058823529411764| 0.9195979899497487| 0.5245901639344263|                0.0|                0.0|0.34724292101341286|  0.2536293766011956|0.18333333333333332|\n",
      "|0.058823529411764705| 0.4472361809045226| 0.5409836065573771|0.23232323232323232| 0.1111111111111111|0.41877794336810736|0.038001707941929974|                0.0|\n",
      "|                 0.0| 0.6884422110552764|0.32786885245901637|0.35353535353535354|0.19858156028368795| 0.6423248882265277|  0.9436379163108454|                0.2|\n",
      "| 0.29411764705882354| 0.5829145728643216| 0.6065573770491803|                0.0|                0.0| 0.3815201192250373|0.052519214346712216|               0.15|\n",
      "| 0.17647058823529413|0.39195979899497485| 0.4098360655737705|0.32323232323232326|0.10401891252955082| 0.4619970193740686| 0.07258753202391117|0.08333333333333333|\n",
      "|  0.5882352941176471| 0.5778894472361809|                0.0|                0.0|                0.0|  0.526080476900149|0.023911187019641334|0.13333333333333333|\n",
      "| 0.11764705882352941| 0.9899497487437185| 0.5737704918032787|0.45454545454545453| 0.6418439716312057| 0.4545454545454546|0.034158838599487616| 0.5333333333333333|\n",
      "| 0.47058823529411764|  0.628140703517588| 0.7868852459016393|                0.0|                0.0|                0.0| 0.06575576430401367|               0.55|\n",
      "| 0.23529411764705882| 0.5527638190954773| 0.7540983606557377|                0.0|                0.0| 0.5603576751117736| 0.04824935952177626|               0.15|\n",
      "|  0.5882352941176471| 0.8442211055276382| 0.6065573770491803|                0.0|                0.0| 0.5663189269746647|  0.1959863364645602|0.21666666666666667|\n",
      "|  0.5882352941176471| 0.6984924623115578| 0.6557377049180327|                0.0|                0.0|0.40387481371087935|  0.5819812126387702|                0.6|\n",
      "|0.058823529411764705|  0.949748743718593| 0.4918032786885246|0.23232323232323232|                1.0| 0.4485842026825634| 0.13663535439795046| 0.6333333333333333|\n",
      "| 0.29411764705882354| 0.8341708542713567| 0.5901639344262295| 0.1919191919191919|0.20685579196217493| 0.3845007451564829| 0.21733561058923997|                0.5|\n",
      "|  0.4117647058823529| 0.5025125628140703|                0.0|                0.0|                0.0|0.44709388971684055| 0.17335610589239964|0.18333333333333332|\n",
      "|                 0.0|  0.592964824120603| 0.6885245901639344|0.47474747474747475| 0.2718676122931442| 0.6825633383010432| 0.20196413321947054|0.16666666666666666|\n",
      "|  0.4117647058823529| 0.5376884422110553| 0.6065573770491803|                0.0|                0.0| 0.4411326378539494| 0.07514944491887275|0.16666666666666666|\n",
      "|0.058823529411764705| 0.5175879396984925| 0.2459016393442623| 0.3838383838383838|0.09810874704491726| 0.6453055141579732| 0.04483347566182749|                0.2|\n",
      "|0.058823529411764705| 0.5778894472361809| 0.5737704918032787|0.30303030303030304|0.11347517730496454| 0.5156482861400895| 0.19257045260461145|0.18333333333333332|\n",
      "+--------------------+-------------------+-------------------+-------------------+-------------------+-------------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "minmax_scaled_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_scaled_df.coalesce(1).write.csv('NormalizedFile.csv', header=True) # One resulting file in the resulting directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Q1. Answer__:\n",
    "I have used the PySpark write method instead of converting to Pandas dataframe for practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Q2__. Z-score normalization:\n",
    "Use Spark API to transform all numeric columns using z-score approach. Then store all normalized columns except the class column in a separate file (name it ZSCORENormalizedFile.csv), the file should include 8 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "numerical_columns = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\"]\n",
    "\n",
    "# Relied on this StackOverflow answer on to run MinMaxScaler on multiple columns\n",
    "#  to keep the 8 columns intact: https://stackoverflow.com/a/60281624\n",
    "vector_assemblers = [\n",
    "    VectorAssembler(inputCols=[column], outputCol=column + \"_vector\")\n",
    "    for column in numerical_columns\n",
    "]\n",
    "\n",
    "standard_scalers = [\n",
    "    # Standardize to have unit standard deviation and zero mean\n",
    "    StandardScaler(inputCol=column + \"_vector\", outputCol=column + \"_scaled\", withStd=True, withMean=True)\n",
    "    for column in numerical_columns\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(stages=vector_assemblers + standard_scalers)\n",
    "scaler_model = pipeline.fit(df)\n",
    "\n",
    "standard_scaled_df = scaler_model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [column for column in numerical_columns] + [f'{column}_vector' for column in numerical_columns] + ['Class']\n",
    "standard_scaled_df = standard_scaled_df.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- A_scaled: vector (nullable = true)\n",
      " |-- B_scaled: vector (nullable = true)\n",
      " |-- C_scaled: vector (nullable = true)\n",
      " |-- D_scaled: vector (nullable = true)\n",
      " |-- E_scaled: vector (nullable = true)\n",
      " |-- F_scaled: vector (nullable = true)\n",
      " |-- G_scaled: vector (nullable = true)\n",
      " |-- H_scaled: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "standard_scaled_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+----------------------+----------------------+----------------------+---------------------+----------------------+----------------------+-----------------------+\n",
      "|A_scaled              |B_scaled              |C_scaled              |D_scaled              |E_scaled             |F_scaled              |G_scaled              |H_scaled               |\n",
      "+----------------------+----------------------+----------------------+----------------------+---------------------+----------------------+----------------------+-----------------------+\n",
      "|[0.6395304921176561]  |[0.84777132058967]    |[0.14954329852954068] |[0.9066790623472516]  |[-0.69243932472413]  |[0.2038799072674687]  |[0.46818687022979555] |[1.4250667195933635]   |\n",
      "|[-0.8443348188985361] |[-1.1226647449053908] |[-0.16044119073007856]|[0.5305558070991296]  |[-0.69243932472413]  |[-0.6839762138098171] |[-0.36482303037766123]|[-0.19054772934660194] |\n",
      "|[1.2330766165241331]  |[1.9424580236424815]  |[-0.2637693538166183] |[-1.28737325993346]   |[-0.69243932472413]  |[-1.102536956603395]  |[0.6040037018505766]  |[-0.10551538992870904] |\n",
      "|[-0.8443348188985361] |[-0.9975576931279265] |[-0.16044119073007856]|[0.1544325518510076]  |[0.12322134378881598]|[-0.49372133072182733]|[-0.9201629641159655] |[-1.040871123525531]   |\n",
      "|[-1.1411078811017745] |[0.5037269282016436]  |[-1.5037073108550953] |[0.9066790623472516]  |[0.7653371892139011] |[1.408827500158071]   |[5.481337032943511]   |[-0.020483050510816128]|\n",
      "|[0.3427574299144177]  |[-0.15308509363004338]|[0.25287146161608043] |[-1.28737325993346]   |[-0.69243932472413]  |[-0.8108128025351437] |[-0.8175458024469311] |[-0.27558006876449487] |\n",
      "|[-0.2507886944920592] |[-1.341602085515953]  |[-0.9870664954223966] |[0.7186174347231906]  |[0.07115789686245773]|[-0.1258952234183805] |[-0.6756926671985599] |[-0.6157094264360665]  |\n",
      "|[1.82662274093061]    |[-0.18436185657440943]|[-3.57027057258589]   |[-1.28737325993346]   |[-0.69243932472413]  |[0.4195021081005233]  |[-1.019761973971205]  |[-0.36061240818238777] |\n",
      "|[-0.5475617566952977] |[2.3803327048636063]  |[0.046215135443000925]|[1.533551154427455]   |[4.019302622111292]  |[-0.18931351778104377]|[-0.9473263304401218] |[1.6801637378470422]   |\n",
      "|[1.2330766165241331]  |[0.128405772869251]   |[1.3894812555680176]  |[-1.28737325993346]   |[-0.69243932472413]  |[-4.057829473903504]  |[-0.723983096219282]  |[1.765196077264935]    |\n",
      "|[0.045984367711179225]|[-0.34074567129623967]|[1.1828249293949382]  |[-1.28737325993346]   |[-0.69243932472413]  |[0.7112262621687749]  |[-0.8477273205848824] |[-0.27558006876449487] |\n",
      "|[1.82662274093061]    |[1.4733065794769908]  |[0.25287146161608043] |[-1.28737325993346]   |[-0.69243932472413]  |[0.7619608976589054]  |[0.19655320698823367] |[0.06454928890707679]  |\n",
      "|[1.82662274093061]    |[0.5662804540903756]  |[0.5628559508756996]  |[-1.28737325993346]   |[-0.69243932472413]  |[-0.6205579194471539] |[2.924962446659034]   |[2.0202930955186136]   |\n",
      "|[-0.8443348188985361] |[2.130118601308678]   |[-0.4704256799896978] |[0.1544325518510076]  |[6.648506691892384]  |[-0.2400481532711742] |[-0.22296989512928989]|[2.1903577743544]      |\n",
      "|[0.3427574299144177]  |[1.4107530535882589]  |[0.14954329852954068] |[-0.09631628498107372]|[0.8260778772946524] |[-0.7854454847900785] |[0.3474607976779901]  |[1.5100990590112564]   |\n",
      "|[0.9363035543208946]  |[-0.6535133007399001] |[-3.57027057258589]   |[-1.28737325993346]   |[-0.69243932472413]  |[-0.25273181214370705]|[0.03659116085709147] |[-0.10551538992870904] |\n",
      "|[-1.1411078811017745] |[-0.0905315677413113] |[0.7695122770487791]  |[1.6589255728434955]  |[1.30332614078627]   |[1.751286289716452]   |[0.23880733238136556] |[-0.19054772934660194] |\n",
      "|[0.9363035543208946]  |[-0.4345759601293378] |[0.25287146161608043] |[-1.28737325993346]   |[-0.69243932472413]  |[-0.3034664476338375] |[-0.6575837563157891] |[-0.19054772934660194] |\n",
      "|[-0.8443348188985361] |[-0.5596830119068019] |[-2.0203481262877943] |[1.0947406899713126]  |[0.02777169109049252]|[1.4341948179031356]  |[-0.8718725350952435] |[-0.020483050510816128]|\n",
      "|[-0.8443348188985361] |[-0.18436185657440943]|[0.046215135443000925]|[0.5932430163071499]  |[0.14057582609760208]|[0.33071649599279523] |[0.17240799247787258] |[-0.10551538992870904] |\n",
      "+----------------------+----------------------+----------------------+----------------------+---------------------+----------------------+----------------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "standard_scaled_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing column data type from vector to double for pyspark csv write to occur without errors\n",
    "#  https://stackoverflow.com/a/51842141\n",
    "#  https://stackoverflow.com/a/46890719\n",
    "#  https://stackoverflow.com/a/61009640\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "cast_from_vector_to_double = F.udf(lambda x : x.toArray().tolist()[0], DoubleType())\n",
    "\n",
    "for column_name in minmax_scaled_df.columns:\n",
    "    standard_scaled_df = standard_scaled_df.withColumn(column_name, cast_from_vector_to_double(column_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+\n",
      "|            A_scaled|            B_scaled|            C_scaled|            D_scaled|           E_scaled|            F_scaled|            G_scaled|            H_scaled|\n",
      "+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+\n",
      "|  0.6395304921176561|    0.84777132058967| 0.14954329852954068|  0.9066790623472516|  -0.69243932472413|  0.2038799072674687| 0.46818687022979555|  1.4250667195933635|\n",
      "| -0.8443348188985361| -1.1226647449053908|-0.16044119073007856|  0.5305558070991296|  -0.69243932472413| -0.6839762138098171|-0.36482303037766123|-0.19054772934660194|\n",
      "|  1.2330766165241331|  1.9424580236424815| -0.2637693538166183|   -1.28737325993346|  -0.69243932472413|  -1.102536956603395|  0.6040037018505766|-0.10551538992870904|\n",
      "| -0.8443348188985361| -0.9975576931279265|-0.16044119073007856|  0.1544325518510076|0.12322134378881598|-0.49372133072182733| -0.9201629641159655|  -1.040871123525531|\n",
      "| -1.1411078811017745|  0.5037269282016436| -1.5037073108550953|  0.9066790623472516| 0.7653371892139011|   1.408827500158071|   5.481337032943511|-0.02048305051081...|\n",
      "|  0.3427574299144177|-0.15308509363004338| 0.25287146161608043|   -1.28737325993346|  -0.69243932472413| -0.8108128025351437| -0.8175458024469311|-0.27558006876449487|\n",
      "| -0.2507886944920592|  -1.341602085515953| -0.9870664954223966|  0.7186174347231906|0.07115789686245773| -0.1258952234183805| -0.6756926671985599| -0.6157094264360665|\n",
      "|    1.82662274093061|-0.18436185657440943|   -3.57027057258589|   -1.28737325993346|  -0.69243932472413|  0.4195021081005233|  -1.019761973971205|-0.36061240818238777|\n",
      "| -0.5475617566952977|  2.3803327048636063|0.046215135443000925|   1.533551154427455|  4.019302622111292|-0.18931351778104377| -0.9473263304401218|  1.6801637378470422|\n",
      "|  1.2330766165241331|   0.128405772869251|  1.3894812555680176|   -1.28737325993346|  -0.69243932472413|  -4.057829473903504|  -0.723983096219282|   1.765196077264935|\n",
      "|0.045984367711179225|-0.34074567129623967|  1.1828249293949382|   -1.28737325993346|  -0.69243932472413|  0.7112262621687749| -0.8477273205848824|-0.27558006876449487|\n",
      "|    1.82662274093061|  1.4733065794769908| 0.25287146161608043|   -1.28737325993346|  -0.69243932472413|  0.7619608976589054| 0.19655320698823367| 0.06454928890707679|\n",
      "|    1.82662274093061|  0.5662804540903756|  0.5628559508756996|   -1.28737325993346|  -0.69243932472413| -0.6205579194471539|   2.924962446659034|  2.0202930955186136|\n",
      "| -0.8443348188985361|   2.130118601308678| -0.4704256799896978|  0.1544325518510076|  6.648506691892384| -0.2400481532711742|-0.22296989512928989|     2.1903577743544|\n",
      "|  0.3427574299144177|  1.4107530535882589| 0.14954329852954068|-0.09631628498107372| 0.8260778772946524| -0.7854454847900785|  0.3474607976779901|  1.5100990590112564|\n",
      "|  0.9363035543208946| -0.6535133007399001|   -3.57027057258589|   -1.28737325993346|  -0.69243932472413|-0.25273181214370705| 0.03659116085709147|-0.10551538992870904|\n",
      "| -1.1411078811017745| -0.0905315677413113|  0.7695122770487791|  1.6589255728434955|   1.30332614078627|   1.751286289716452| 0.23880733238136556|-0.19054772934660194|\n",
      "|  0.9363035543208946| -0.4345759601293378| 0.25287146161608043|   -1.28737325993346|  -0.69243932472413| -0.3034664476338375| -0.6575837563157891|-0.19054772934660194|\n",
      "| -0.8443348188985361| -0.5596830119068019| -2.0203481262877943|  1.0947406899713126|0.02777169109049252|  1.4341948179031356| -0.8718725350952435|-0.02048305051081...|\n",
      "| -0.8443348188985361|-0.18436185657440943|0.046215135443000925|  0.5932430163071499|0.14057582609760208| 0.33071649599279523| 0.17240799247787258|-0.10551538992870904|\n",
      "+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "standard_scaled_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaled_df.coalesce(1).write.csv('ZSCORENormalizedFile.csv', header=True) # One resulting file in the resulting directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Q2. Answer__:\n",
    "I have used the PySpark write method instead of converting to Pandas dataframe for practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Q3__. K-means on Normalized and Scaled features:\n",
    "Use Spark API to to train kmeans clustering model to cluster the dataset file (NormalizedFile.csv) and then the dataset file (ZSCORENormalizedFile.csv) by using k=2 for each model, and display the cluster number for all rows in both cases. Compare the result for clustering ZSCORENormalizedFile.csv and NormalizedFile.csv. Can Identify which model did better and why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __3.1- Min-max scaled data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_scaled_df = spark.read.csv(\"NormalizedFile.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+-------------------+-------------------+-------------------+--------------------+-------------------+\n",
      "|            A_scaled|           B_scaled|           C_scaled|           D_scaled|           E_scaled|           F_scaled|            G_scaled|           H_scaled|\n",
      "+--------------------+-------------------+-------------------+-------------------+-------------------+-------------------+--------------------+-------------------+\n",
      "| 0.35294117647058826| 0.7437185929648241| 0.5901639344262295|0.35353535353535354|                0.0| 0.5007451564828614| 0.23441502988898377|0.48333333333333334|\n",
      "|0.058823529411764705| 0.4271356783919598| 0.5409836065573771|0.29292929292929293|                0.0| 0.3964232488822653| 0.11656703672075147|0.16666666666666666|\n",
      "| 0.47058823529411764| 0.9195979899497487| 0.5245901639344263|                0.0|                0.0|0.34724292101341286|  0.2536293766011956|0.18333333333333332|\n",
      "|0.058823529411764705| 0.4472361809045226| 0.5409836065573771|0.23232323232323232| 0.1111111111111111|0.41877794336810736|0.038001707941929974|                0.0|\n",
      "|                 0.0| 0.6884422110552764|0.32786885245901637|0.35353535353535354|0.19858156028368795| 0.6423248882265277|  0.9436379163108454|                0.2|\n",
      "| 0.29411764705882354| 0.5829145728643216| 0.6065573770491803|                0.0|                0.0| 0.3815201192250373|0.052519214346712216|               0.15|\n",
      "| 0.17647058823529413|0.39195979899497485| 0.4098360655737705|0.32323232323232326|0.10401891252955082| 0.4619970193740686| 0.07258753202391117|0.08333333333333333|\n",
      "|  0.5882352941176471| 0.5778894472361809|                0.0|                0.0|                0.0|  0.526080476900149|0.023911187019641334|0.13333333333333333|\n",
      "| 0.11764705882352941| 0.9899497487437185| 0.5737704918032787|0.45454545454545453| 0.6418439716312057| 0.4545454545454546|0.034158838599487616| 0.5333333333333333|\n",
      "| 0.47058823529411764|  0.628140703517588| 0.7868852459016393|                0.0|                0.0|                0.0| 0.06575576430401367|               0.55|\n",
      "| 0.23529411764705882| 0.5527638190954773| 0.7540983606557377|                0.0|                0.0| 0.5603576751117736| 0.04824935952177626|               0.15|\n",
      "|  0.5882352941176471| 0.8442211055276382| 0.6065573770491803|                0.0|                0.0| 0.5663189269746647|  0.1959863364645602|0.21666666666666667|\n",
      "|  0.5882352941176471| 0.6984924623115578| 0.6557377049180327|                0.0|                0.0|0.40387481371087935|  0.5819812126387702|                0.6|\n",
      "|0.058823529411764705|  0.949748743718593| 0.4918032786885246|0.23232323232323232|                1.0| 0.4485842026825634| 0.13663535439795046| 0.6333333333333333|\n",
      "| 0.29411764705882354| 0.8341708542713567| 0.5901639344262295| 0.1919191919191919|0.20685579196217493| 0.3845007451564829| 0.21733561058923997|                0.5|\n",
      "|  0.4117647058823529| 0.5025125628140703|                0.0|                0.0|                0.0|0.44709388971684055| 0.17335610589239964|0.18333333333333332|\n",
      "|                 0.0|  0.592964824120603| 0.6885245901639344|0.47474747474747475| 0.2718676122931442| 0.6825633383010432| 0.20196413321947054|0.16666666666666666|\n",
      "|  0.4117647058823529| 0.5376884422110553| 0.6065573770491803|                0.0|                0.0| 0.4411326378539494| 0.07514944491887275|0.16666666666666666|\n",
      "|0.058823529411764705| 0.5175879396984925| 0.2459016393442623| 0.3838383838383838|0.09810874704491726| 0.6453055141579732| 0.04483347566182749|                0.2|\n",
      "|0.058823529411764705| 0.5778894472361809| 0.5737704918032787|0.30303030303030304|0.11347517730496454| 0.5156482861400895| 0.19257045260461145|0.18333333333333332|\n",
      "+--------------------+-------------------+-------------------+-------------------+-------------------+-------------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "minmax_scaled_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- A_scaled: double (nullable = true)\n",
      " |-- B_scaled: double (nullable = true)\n",
      " |-- C_scaled: double (nullable = true)\n",
      " |-- D_scaled: double (nullable = true)\n",
      " |-- E_scaled: double (nullable = true)\n",
      " |-- F_scaled: double (nullable = true)\n",
      " |-- G_scaled: double (nullable = true)\n",
      " |-- H_scaled: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "minmax_scaled_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 'features' vector column\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "vector_assembler = VectorAssembler(inputCols=minmax_scaled_df.columns, outputCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[vector_assembler])\n",
    "pipeline_model = pipeline.fit(minmax_scaled_df)\n",
    "\n",
    "minmax_scaled_df = pipeline_model.transform(minmax_scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- A_scaled: double (nullable = true)\n",
      " |-- B_scaled: double (nullable = true)\n",
      " |-- C_scaled: double (nullable = true)\n",
      " |-- D_scaled: double (nullable = true)\n",
      " |-- E_scaled: double (nullable = true)\n",
      " |-- F_scaled: double (nullable = true)\n",
      " |-- G_scaled: double (nullable = true)\n",
      " |-- H_scaled: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "minmax_scaled_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+-------------------+-------------------+-------------------+--------------------+-------------------+--------------------+\n",
      "|            A_scaled|           B_scaled|           C_scaled|           D_scaled|           E_scaled|           F_scaled|            G_scaled|           H_scaled|            features|\n",
      "+--------------------+-------------------+-------------------+-------------------+-------------------+-------------------+--------------------+-------------------+--------------------+\n",
      "| 0.35294117647058826| 0.7437185929648241| 0.5901639344262295|0.35353535353535354|                0.0| 0.5007451564828614| 0.23441502988898377|0.48333333333333334|[0.35294117647058...|\n",
      "|0.058823529411764705| 0.4271356783919598| 0.5409836065573771|0.29292929292929293|                0.0| 0.3964232488822653| 0.11656703672075147|0.16666666666666666|[0.05882352941176...|\n",
      "| 0.47058823529411764| 0.9195979899497487| 0.5245901639344263|                0.0|                0.0|0.34724292101341286|  0.2536293766011956|0.18333333333333332|[0.47058823529411...|\n",
      "|0.058823529411764705| 0.4472361809045226| 0.5409836065573771|0.23232323232323232| 0.1111111111111111|0.41877794336810736|0.038001707941929974|                0.0|[0.05882352941176...|\n",
      "|                 0.0| 0.6884422110552764|0.32786885245901637|0.35353535353535354|0.19858156028368795| 0.6423248882265277|  0.9436379163108454|                0.2|[0.0,0.6884422110...|\n",
      "| 0.29411764705882354| 0.5829145728643216| 0.6065573770491803|                0.0|                0.0| 0.3815201192250373|0.052519214346712216|               0.15|[0.29411764705882...|\n",
      "| 0.17647058823529413|0.39195979899497485| 0.4098360655737705|0.32323232323232326|0.10401891252955082| 0.4619970193740686| 0.07258753202391117|0.08333333333333333|[0.17647058823529...|\n",
      "|  0.5882352941176471| 0.5778894472361809|                0.0|                0.0|                0.0|  0.526080476900149|0.023911187019641334|0.13333333333333333|[0.58823529411764...|\n",
      "| 0.11764705882352941| 0.9899497487437185| 0.5737704918032787|0.45454545454545453| 0.6418439716312057| 0.4545454545454546|0.034158838599487616| 0.5333333333333333|[0.11764705882352...|\n",
      "| 0.47058823529411764|  0.628140703517588| 0.7868852459016393|                0.0|                0.0|                0.0| 0.06575576430401367|               0.55|[0.47058823529411...|\n",
      "| 0.23529411764705882| 0.5527638190954773| 0.7540983606557377|                0.0|                0.0| 0.5603576751117736| 0.04824935952177626|               0.15|[0.23529411764705...|\n",
      "|  0.5882352941176471| 0.8442211055276382| 0.6065573770491803|                0.0|                0.0| 0.5663189269746647|  0.1959863364645602|0.21666666666666667|[0.58823529411764...|\n",
      "|  0.5882352941176471| 0.6984924623115578| 0.6557377049180327|                0.0|                0.0|0.40387481371087935|  0.5819812126387702|                0.6|[0.58823529411764...|\n",
      "|0.058823529411764705|  0.949748743718593| 0.4918032786885246|0.23232323232323232|                1.0| 0.4485842026825634| 0.13663535439795046| 0.6333333333333333|[0.05882352941176...|\n",
      "| 0.29411764705882354| 0.8341708542713567| 0.5901639344262295| 0.1919191919191919|0.20685579196217493| 0.3845007451564829| 0.21733561058923997|                0.5|[0.29411764705882...|\n",
      "|  0.4117647058823529| 0.5025125628140703|                0.0|                0.0|                0.0|0.44709388971684055| 0.17335610589239964|0.18333333333333332|[0.41176470588235...|\n",
      "|                 0.0|  0.592964824120603| 0.6885245901639344|0.47474747474747475| 0.2718676122931442| 0.6825633383010432| 0.20196413321947054|0.16666666666666666|[0.0,0.5929648241...|\n",
      "|  0.4117647058823529| 0.5376884422110553| 0.6065573770491803|                0.0|                0.0| 0.4411326378539494| 0.07514944491887275|0.16666666666666666|[0.41176470588235...|\n",
      "|0.058823529411764705| 0.5175879396984925| 0.2459016393442623| 0.3838383838383838|0.09810874704491726| 0.6453055141579732| 0.04483347566182749|                0.2|[0.05882352941176...|\n",
      "|0.058823529411764705| 0.5778894472361809| 0.5737704918032787|0.30303030303030304|0.11347517730496454| 0.5156482861400895| 0.19257045260461145|0.18333333333333332|[0.05882352941176...|\n",
      "+--------------------+-------------------+-------------------+-------------------+-------------------+-------------------+--------------------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "minmax_scaled_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "# Added random seed value 420 for reproducible results\n",
    "kmeans = KMeans(\n",
    "    featuresCol='features',\n",
    "    predictionCol='predicted_cluster_id',\n",
    "    k=2,\n",
    "    tol=0.0001,\n",
    "    maxIter=1000,\n",
    "    seed=420,\n",
    "    distanceMeasure='euclidean'\n",
    ")\n",
    "\n",
    "kmeans_model_minmax = kmeans.fit(minmax_scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_scaled_df = kmeans_model_minmax.transform(minmax_scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+-------------------+-------------------+-------------------+--------------------+-------------------+--------------------+--------------------+\n",
      "|            A_scaled|           B_scaled|           C_scaled|           D_scaled|           E_scaled|           F_scaled|            G_scaled|           H_scaled|            features|predicted_cluster_id|\n",
      "+--------------------+-------------------+-------------------+-------------------+-------------------+-------------------+--------------------+-------------------+--------------------+--------------------+\n",
      "| 0.35294117647058826| 0.7437185929648241| 0.5901639344262295|0.35353535353535354|                0.0| 0.5007451564828614| 0.23441502988898377|0.48333333333333334|[0.35294117647058...|                   0|\n",
      "|0.058823529411764705| 0.4271356783919598| 0.5409836065573771|0.29292929292929293|                0.0| 0.3964232488822653| 0.11656703672075147|0.16666666666666666|[0.05882352941176...|                   1|\n",
      "| 0.47058823529411764| 0.9195979899497487| 0.5245901639344263|                0.0|                0.0|0.34724292101341286|  0.2536293766011956|0.18333333333333332|[0.47058823529411...|                   0|\n",
      "|0.058823529411764705| 0.4472361809045226| 0.5409836065573771|0.23232323232323232| 0.1111111111111111|0.41877794336810736|0.038001707941929974|                0.0|[0.05882352941176...|                   1|\n",
      "|                 0.0| 0.6884422110552764|0.32786885245901637|0.35353535353535354|0.19858156028368795| 0.6423248882265277|  0.9436379163108454|                0.2|[0.0,0.6884422110...|                   1|\n",
      "| 0.29411764705882354| 0.5829145728643216| 0.6065573770491803|                0.0|                0.0| 0.3815201192250373|0.052519214346712216|               0.15|[0.29411764705882...|                   1|\n",
      "| 0.17647058823529413|0.39195979899497485| 0.4098360655737705|0.32323232323232326|0.10401891252955082| 0.4619970193740686| 0.07258753202391117|0.08333333333333333|[0.17647058823529...|                   1|\n",
      "|  0.5882352941176471| 0.5778894472361809|                0.0|                0.0|                0.0|  0.526080476900149|0.023911187019641334|0.13333333333333333|[0.58823529411764...|                   0|\n",
      "| 0.11764705882352941| 0.9899497487437185| 0.5737704918032787|0.45454545454545453| 0.6418439716312057| 0.4545454545454546|0.034158838599487616| 0.5333333333333333|[0.11764705882352...|                   0|\n",
      "| 0.47058823529411764|  0.628140703517588| 0.7868852459016393|                0.0|                0.0|                0.0| 0.06575576430401367|               0.55|[0.47058823529411...|                   0|\n",
      "| 0.23529411764705882| 0.5527638190954773| 0.7540983606557377|                0.0|                0.0| 0.5603576751117736| 0.04824935952177626|               0.15|[0.23529411764705...|                   1|\n",
      "|  0.5882352941176471| 0.8442211055276382| 0.6065573770491803|                0.0|                0.0| 0.5663189269746647|  0.1959863364645602|0.21666666666666667|[0.58823529411764...|                   0|\n",
      "|  0.5882352941176471| 0.6984924623115578| 0.6557377049180327|                0.0|                0.0|0.40387481371087935|  0.5819812126387702|                0.6|[0.58823529411764...|                   0|\n",
      "|0.058823529411764705|  0.949748743718593| 0.4918032786885246|0.23232323232323232|                1.0| 0.4485842026825634| 0.13663535439795046| 0.6333333333333333|[0.05882352941176...|                   0|\n",
      "| 0.29411764705882354| 0.8341708542713567| 0.5901639344262295| 0.1919191919191919|0.20685579196217493| 0.3845007451564829| 0.21733561058923997|                0.5|[0.29411764705882...|                   0|\n",
      "|  0.4117647058823529| 0.5025125628140703|                0.0|                0.0|                0.0|0.44709388971684055| 0.17335610589239964|0.18333333333333332|[0.41176470588235...|                   1|\n",
      "|                 0.0|  0.592964824120603| 0.6885245901639344|0.47474747474747475| 0.2718676122931442| 0.6825633383010432| 0.20196413321947054|0.16666666666666666|[0.0,0.5929648241...|                   1|\n",
      "|  0.4117647058823529| 0.5376884422110553| 0.6065573770491803|                0.0|                0.0| 0.4411326378539494| 0.07514944491887275|0.16666666666666666|[0.41176470588235...|                   0|\n",
      "|0.058823529411764705| 0.5175879396984925| 0.2459016393442623| 0.3838383838383838|0.09810874704491726| 0.6453055141579732| 0.04483347566182749|                0.2|[0.05882352941176...|                   1|\n",
      "|0.058823529411764705| 0.5778894472361809| 0.5737704918032787|0.30303030303030304|0.11347517730496454| 0.5156482861400895| 0.19257045260461145|0.18333333333333332|[0.05882352941176...|                   1|\n",
      "+--------------------+-------------------+-------------------+-------------------+-------------------+-------------------+--------------------+-------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "minmax_scaled_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __3.2- Z-score scaled data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaled_df = spark.read.csv(\"ZSCORENormalizedFile.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+\n",
      "|            A_scaled|            B_scaled|            C_scaled|            D_scaled|           E_scaled|            F_scaled|            G_scaled|            H_scaled|\n",
      "+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+\n",
      "|  0.6395304921176561|    0.84777132058967| 0.14954329852954068|  0.9066790623472516|  -0.69243932472413|  0.2038799072674687| 0.46818687022979555|  1.4250667195933635|\n",
      "| -0.8443348188985361| -1.1226647449053908|-0.16044119073007856|  0.5305558070991296|  -0.69243932472413| -0.6839762138098171|-0.36482303037766123|-0.19054772934660194|\n",
      "|  1.2330766165241331|  1.9424580236424815| -0.2637693538166183|   -1.28737325993346|  -0.69243932472413|  -1.102536956603395|  0.6040037018505766|-0.10551538992870904|\n",
      "| -0.8443348188985361| -0.9975576931279265|-0.16044119073007856|  0.1544325518510076|0.12322134378881598|-0.49372133072182733| -0.9201629641159655|  -1.040871123525531|\n",
      "| -1.1411078811017745|  0.5037269282016436| -1.5037073108550953|  0.9066790623472516| 0.7653371892139011|   1.408827500158071|   5.481337032943511|-0.02048305051081...|\n",
      "|  0.3427574299144177|-0.15308509363004338| 0.25287146161608043|   -1.28737325993346|  -0.69243932472413| -0.8108128025351437| -0.8175458024469311|-0.27558006876449487|\n",
      "| -0.2507886944920592|  -1.341602085515953| -0.9870664954223966|  0.7186174347231906|0.07115789686245773| -0.1258952234183805| -0.6756926671985599| -0.6157094264360665|\n",
      "|    1.82662274093061|-0.18436185657440943|   -3.57027057258589|   -1.28737325993346|  -0.69243932472413|  0.4195021081005233|  -1.019761973971205|-0.36061240818238777|\n",
      "| -0.5475617566952977|  2.3803327048636063|0.046215135443000925|   1.533551154427455|  4.019302622111292|-0.18931351778104377| -0.9473263304401218|  1.6801637378470422|\n",
      "|  1.2330766165241331|   0.128405772869251|  1.3894812555680176|   -1.28737325993346|  -0.69243932472413|  -4.057829473903504|  -0.723983096219282|   1.765196077264935|\n",
      "|0.045984367711179225|-0.34074567129623967|  1.1828249293949382|   -1.28737325993346|  -0.69243932472413|  0.7112262621687749| -0.8477273205848824|-0.27558006876449487|\n",
      "|    1.82662274093061|  1.4733065794769908| 0.25287146161608043|   -1.28737325993346|  -0.69243932472413|  0.7619608976589054| 0.19655320698823367| 0.06454928890707679|\n",
      "|    1.82662274093061|  0.5662804540903756|  0.5628559508756996|   -1.28737325993346|  -0.69243932472413| -0.6205579194471539|   2.924962446659034|  2.0202930955186136|\n",
      "| -0.8443348188985361|   2.130118601308678| -0.4704256799896978|  0.1544325518510076|  6.648506691892384| -0.2400481532711742|-0.22296989512928989|     2.1903577743544|\n",
      "|  0.3427574299144177|  1.4107530535882589| 0.14954329852954068|-0.09631628498107372| 0.8260778772946524| -0.7854454847900785|  0.3474607976779901|  1.5100990590112564|\n",
      "|  0.9363035543208946| -0.6535133007399001|   -3.57027057258589|   -1.28737325993346|  -0.69243932472413|-0.25273181214370705| 0.03659116085709147|-0.10551538992870904|\n",
      "| -1.1411078811017745| -0.0905315677413113|  0.7695122770487791|  1.6589255728434955|   1.30332614078627|   1.751286289716452| 0.23880733238136556|-0.19054772934660194|\n",
      "|  0.9363035543208946| -0.4345759601293378| 0.25287146161608043|   -1.28737325993346|  -0.69243932472413| -0.3034664476338375| -0.6575837563157891|-0.19054772934660194|\n",
      "| -0.8443348188985361| -0.5596830119068019| -2.0203481262877943|  1.0947406899713126|0.02777169109049252|  1.4341948179031356| -0.8718725350952435|-0.02048305051081...|\n",
      "| -0.8443348188985361|-0.18436185657440943|0.046215135443000925|  0.5932430163071499|0.14057582609760208| 0.33071649599279523| 0.17240799247787258|-0.10551538992870904|\n",
      "+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "standard_scaled_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- A_scaled: double (nullable = true)\n",
      " |-- B_scaled: double (nullable = true)\n",
      " |-- C_scaled: double (nullable = true)\n",
      " |-- D_scaled: double (nullable = true)\n",
      " |-- E_scaled: double (nullable = true)\n",
      " |-- F_scaled: double (nullable = true)\n",
      " |-- G_scaled: double (nullable = true)\n",
      " |-- H_scaled: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "standard_scaled_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 'features' vector column\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "vector_assembler = VectorAssembler(inputCols=standard_scaled_df.columns, outputCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[vector_assembler])\n",
    "pipeline_model = pipeline.fit(standard_scaled_df)\n",
    "\n",
    "standard_scaled_df = pipeline_model.transform(standard_scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- A_scaled: double (nullable = true)\n",
      " |-- B_scaled: double (nullable = true)\n",
      " |-- C_scaled: double (nullable = true)\n",
      " |-- D_scaled: double (nullable = true)\n",
      " |-- E_scaled: double (nullable = true)\n",
      " |-- F_scaled: double (nullable = true)\n",
      " |-- G_scaled: double (nullable = true)\n",
      " |-- H_scaled: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "standard_scaled_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|            A_scaled|            B_scaled|            C_scaled|            D_scaled|           E_scaled|            F_scaled|            G_scaled|            H_scaled|            features|\n",
      "+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  0.6395304921176561|    0.84777132058967| 0.14954329852954068|  0.9066790623472516|  -0.69243932472413|  0.2038799072674687| 0.46818687022979555|  1.4250667195933635|[0.63953049211765...|\n",
      "| -0.8443348188985361| -1.1226647449053908|-0.16044119073007856|  0.5305558070991296|  -0.69243932472413| -0.6839762138098171|-0.36482303037766123|-0.19054772934660194|[-0.8443348188985...|\n",
      "|  1.2330766165241331|  1.9424580236424815| -0.2637693538166183|   -1.28737325993346|  -0.69243932472413|  -1.102536956603395|  0.6040037018505766|-0.10551538992870904|[1.23307661652413...|\n",
      "| -0.8443348188985361| -0.9975576931279265|-0.16044119073007856|  0.1544325518510076|0.12322134378881598|-0.49372133072182733| -0.9201629641159655|  -1.040871123525531|[-0.8443348188985...|\n",
      "| -1.1411078811017745|  0.5037269282016436| -1.5037073108550953|  0.9066790623472516| 0.7653371892139011|   1.408827500158071|   5.481337032943511|-0.02048305051081...|[-1.1411078811017...|\n",
      "|  0.3427574299144177|-0.15308509363004338| 0.25287146161608043|   -1.28737325993346|  -0.69243932472413| -0.8108128025351437| -0.8175458024469311|-0.27558006876449487|[0.34275742991441...|\n",
      "| -0.2507886944920592|  -1.341602085515953| -0.9870664954223966|  0.7186174347231906|0.07115789686245773| -0.1258952234183805| -0.6756926671985599| -0.6157094264360665|[-0.2507886944920...|\n",
      "|    1.82662274093061|-0.18436185657440943|   -3.57027057258589|   -1.28737325993346|  -0.69243932472413|  0.4195021081005233|  -1.019761973971205|-0.36061240818238777|[1.82662274093061...|\n",
      "| -0.5475617566952977|  2.3803327048636063|0.046215135443000925|   1.533551154427455|  4.019302622111292|-0.18931351778104377| -0.9473263304401218|  1.6801637378470422|[-0.5475617566952...|\n",
      "|  1.2330766165241331|   0.128405772869251|  1.3894812555680176|   -1.28737325993346|  -0.69243932472413|  -4.057829473903504|  -0.723983096219282|   1.765196077264935|[1.23307661652413...|\n",
      "|0.045984367711179225|-0.34074567129623967|  1.1828249293949382|   -1.28737325993346|  -0.69243932472413|  0.7112262621687749| -0.8477273205848824|-0.27558006876449487|[0.04598436771117...|\n",
      "|    1.82662274093061|  1.4733065794769908| 0.25287146161608043|   -1.28737325993346|  -0.69243932472413|  0.7619608976589054| 0.19655320698823367| 0.06454928890707679|[1.82662274093061...|\n",
      "|    1.82662274093061|  0.5662804540903756|  0.5628559508756996|   -1.28737325993346|  -0.69243932472413| -0.6205579194471539|   2.924962446659034|  2.0202930955186136|[1.82662274093061...|\n",
      "| -0.8443348188985361|   2.130118601308678| -0.4704256799896978|  0.1544325518510076|  6.648506691892384| -0.2400481532711742|-0.22296989512928989|     2.1903577743544|[-0.8443348188985...|\n",
      "|  0.3427574299144177|  1.4107530535882589| 0.14954329852954068|-0.09631628498107372| 0.8260778772946524| -0.7854454847900785|  0.3474607976779901|  1.5100990590112564|[0.34275742991441...|\n",
      "|  0.9363035543208946| -0.6535133007399001|   -3.57027057258589|   -1.28737325993346|  -0.69243932472413|-0.25273181214370705| 0.03659116085709147|-0.10551538992870904|[0.93630355432089...|\n",
      "| -1.1411078811017745| -0.0905315677413113|  0.7695122770487791|  1.6589255728434955|   1.30332614078627|   1.751286289716452| 0.23880733238136556|-0.19054772934660194|[-1.1411078811017...|\n",
      "|  0.9363035543208946| -0.4345759601293378| 0.25287146161608043|   -1.28737325993346|  -0.69243932472413| -0.3034664476338375| -0.6575837563157891|-0.19054772934660194|[0.93630355432089...|\n",
      "| -0.8443348188985361| -0.5596830119068019| -2.0203481262877943|  1.0947406899713126|0.02777169109049252|  1.4341948179031356| -0.8718725350952435|-0.02048305051081...|[-0.8443348188985...|\n",
      "| -0.8443348188985361|-0.18436185657440943|0.046215135443000925|  0.5932430163071499|0.14057582609760208| 0.33071649599279523| 0.17240799247787258|-0.10551538992870904|[-0.8443348188985...|\n",
      "+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "standard_scaled_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "# Added random seed value 420 for reproducible results\n",
    "kmeans = KMeans(\n",
    "    featuresCol='features',\n",
    "    predictionCol='predicted_cluster_id',\n",
    "    k=2,\n",
    "    tol=0.0001,\n",
    "    maxIter=1000,\n",
    "    seed=420,\n",
    "    distanceMeasure='euclidean'\n",
    ")\n",
    "\n",
    "kmeans_model_standard = kmeans.fit(standard_scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaled_df = kmeans_model_standard.transform(standard_scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|            A_scaled|            B_scaled|            C_scaled|            D_scaled|           E_scaled|            F_scaled|            G_scaled|            H_scaled|            features|predicted_cluster_id|\n",
      "+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  0.6395304921176561|    0.84777132058967| 0.14954329852954068|  0.9066790623472516|  -0.69243932472413|  0.2038799072674687| 0.46818687022979555|  1.4250667195933635|[0.63953049211765...|                   1|\n",
      "| -0.8443348188985361| -1.1226647449053908|-0.16044119073007856|  0.5305558070991296|  -0.69243932472413| -0.6839762138098171|-0.36482303037766123|-0.19054772934660194|[-0.8443348188985...|                   0|\n",
      "|  1.2330766165241331|  1.9424580236424815| -0.2637693538166183|   -1.28737325993346|  -0.69243932472413|  -1.102536956603395|  0.6040037018505766|-0.10551538992870904|[1.23307661652413...|                   0|\n",
      "| -0.8443348188985361| -0.9975576931279265|-0.16044119073007856|  0.1544325518510076|0.12322134378881598|-0.49372133072182733| -0.9201629641159655|  -1.040871123525531|[-0.8443348188985...|                   0|\n",
      "| -1.1411078811017745|  0.5037269282016436| -1.5037073108550953|  0.9066790623472516| 0.7653371892139011|   1.408827500158071|   5.481337032943511|-0.02048305051081...|[-1.1411078811017...|                   1|\n",
      "|  0.3427574299144177|-0.15308509363004338| 0.25287146161608043|   -1.28737325993346|  -0.69243932472413| -0.8108128025351437| -0.8175458024469311|-0.27558006876449487|[0.34275742991441...|                   0|\n",
      "| -0.2507886944920592|  -1.341602085515953| -0.9870664954223966|  0.7186174347231906|0.07115789686245773| -0.1258952234183805| -0.6756926671985599| -0.6157094264360665|[-0.2507886944920...|                   0|\n",
      "|    1.82662274093061|-0.18436185657440943|   -3.57027057258589|   -1.28737325993346|  -0.69243932472413|  0.4195021081005233|  -1.019761973971205|-0.36061240818238777|[1.82662274093061...|                   0|\n",
      "| -0.5475617566952977|  2.3803327048636063|0.046215135443000925|   1.533551154427455|  4.019302622111292|-0.18931351778104377| -0.9473263304401218|  1.6801637378470422|[-0.5475617566952...|                   1|\n",
      "|  1.2330766165241331|   0.128405772869251|  1.3894812555680176|   -1.28737325993346|  -0.69243932472413|  -4.057829473903504|  -0.723983096219282|   1.765196077264935|[1.23307661652413...|                   0|\n",
      "|0.045984367711179225|-0.34074567129623967|  1.1828249293949382|   -1.28737325993346|  -0.69243932472413|  0.7112262621687749| -0.8477273205848824|-0.27558006876449487|[0.04598436771117...|                   0|\n",
      "|    1.82662274093061|  1.4733065794769908| 0.25287146161608043|   -1.28737325993346|  -0.69243932472413|  0.7619608976589054| 0.19655320698823367| 0.06454928890707679|[1.82662274093061...|                   0|\n",
      "|    1.82662274093061|  0.5662804540903756|  0.5628559508756996|   -1.28737325993346|  -0.69243932472413| -0.6205579194471539|   2.924962446659034|  2.0202930955186136|[1.82662274093061...|                   0|\n",
      "| -0.8443348188985361|   2.130118601308678| -0.4704256799896978|  0.1544325518510076|  6.648506691892384| -0.2400481532711742|-0.22296989512928989|     2.1903577743544|[-0.8443348188985...|                   1|\n",
      "|  0.3427574299144177|  1.4107530535882589| 0.14954329852954068|-0.09631628498107372| 0.8260778772946524| -0.7854454847900785|  0.3474607976779901|  1.5100990590112564|[0.34275742991441...|                   1|\n",
      "|  0.9363035543208946| -0.6535133007399001|   -3.57027057258589|   -1.28737325993346|  -0.69243932472413|-0.25273181214370705| 0.03659116085709147|-0.10551538992870904|[0.93630355432089...|                   0|\n",
      "| -1.1411078811017745| -0.0905315677413113|  0.7695122770487791|  1.6589255728434955|   1.30332614078627|   1.751286289716452| 0.23880733238136556|-0.19054772934660194|[-1.1411078811017...|                   1|\n",
      "|  0.9363035543208946| -0.4345759601293378| 0.25287146161608043|   -1.28737325993346|  -0.69243932472413| -0.3034664476338375| -0.6575837563157891|-0.19054772934660194|[0.93630355432089...|                   0|\n",
      "| -0.8443348188985361| -0.5596830119068019| -2.0203481262877943|  1.0947406899713126|0.02777169109049252|  1.4341948179031356| -0.8718725350952435|-0.02048305051081...|[-0.8443348188985...|                   1|\n",
      "| -0.8443348188985361|-0.18436185657440943|0.046215135443000925|  0.5932430163071499|0.14057582609760208| 0.33071649599279523| 0.17240799247787258|-0.10551538992870904|[-0.8443348188985...|                   1|\n",
      "+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "standard_scaled_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __3.3- Evaluating KMeans models using the Silhouette measure for clustering results__\n",
    "Reference for using the PySpark ClusteringEvaluator is from the official documentation [here](https://spark.apache.org/docs/latest/ml-clustering.html#k-means) and [here](https://spark.apache.org/docs/2.3.0/api/python/pyspark.ml.html#pyspark.ml.evaluation.ClusteringEvaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "# Evaluate clustering by computing Silhouette score for Clustering results,\n",
    "#  which expects two input columns: prediction and features. The metric computes the Silhouette \n",
    "#  measure using the squared Euclidean distance.\n",
    "\n",
    "# The Silhouette is a measure for the validation of the consistency\n",
    "#  within clusters. It ranges between 1 and -1, where a value close to\n",
    "#  1 means that the points in a cluster are close to the other points\n",
    "#  in the same cluster and far from the points of the other clusters.\n",
    "evaluator = ClusteringEvaluator(\n",
    "    predictionCol=\"predicted_cluster_id\",\n",
    "    featuresCol=\"features\",\n",
    "    metricName=\"silhouette\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min-Max scaled data Silhouette measure with squared euclidean distance = 0.41578027722961913\n",
      "\n",
      "Min-Max scaled data Within set Sum of Squared Errors = 121.25848529922399\n",
      "\n",
      "Cluster Centers for Min-Max scaled KMeans model: \n",
      "[0.43848137 0.66399728 0.61766051 0.17932311 0.08200296 0.48339578\n",
      " 0.1697565  0.4249004 ]\n",
      "[0.12310843 0.58008612 0.54157022 0.22108903 0.1003082  0.47358226\n",
      " 0.16741382 0.09677627]\n"
     ]
    }
   ],
   "source": [
    "silhouette_minmax = evaluator.evaluate(minmax_scaled_df)\n",
    "print(\"Min-Max scaled data Silhouette measure with squared euclidean distance = {}\\n\".format(str(silhouette_minmax)))\n",
    "\n",
    "wssse = kmeans_model_minmax.computeCost(minmax_scaled_df)\n",
    "print(\"Min-Max scaled data Within set Sum of Squared Errors = {}\\n\".format(str(wssse)))\n",
    "\n",
    "centers = kmeans_model_minmax.clusterCenters()\n",
    "print(\"Cluster Centers for Min-Max scaled KMeans model: \")\n",
    "for center in centers:\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard (Z-Score) scaled data Silhouette measure with squared euclidean distance = 0.2758527960262051\n",
      "\n",
      "Standard (Z-Score) scaled data Within set Sum of Squared Errors = 5149.290158623635\n",
      "\n",
      "Cluster Centers for Standard (Z-Score) scaled KMeans model: \n",
      "[-0.05229762 -0.33485589 -0.20886229 -0.5447605  -0.45971271 -0.37122244\n",
      " -0.19806688 -0.0856377 ]\n",
      "[0.07895915 0.50556674 0.3153411  0.82248154 0.69407606 0.5604731\n",
      " 0.29904215 0.12929614]\n"
     ]
    }
   ],
   "source": [
    "silhouette_standard = evaluator.evaluate(standard_scaled_df)\n",
    "print(\"Standard (Z-Score) scaled data Silhouette measure with squared euclidean distance = {}\\n\".format(str(silhouette_standard)))\n",
    "\n",
    "wssse = kmeans_model_standard.computeCost(standard_scaled_df)\n",
    "print(\"Standard (Z-Score) scaled data Within set Sum of Squared Errors = {}\\n\".format(str(wssse)))\n",
    "\n",
    "centers = kmeans_model_standard.clusterCenters()\n",
    "print(\"Cluster Centers for Standard (Z-Score) scaled KMeans model: \")\n",
    "for center in centers:\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Q3. Answer__:\n",
    "Since the Silhouette measure ranges between 1 and -1; where a value close to 1 means that the points in a cluster are close to other points in the same cluster and far from the points of the other clusters. __The greater silhouette measure and the lower Within Set Sum of Squared Error (WSSE) value for the KMeans clustering with the Min-Max scaled data would signify that it outperformed the KMeans clustering with the standard (z-score) scaled data__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Q4__. KNN classifier:\n",
    "Use Spark API to train a KNN model on 75% of the Dataset and provide accuracy and confusion matrix using 25% of the Dataset. Compare the performance of the classifer based on Normalized and Scaled features in NormalizedFile.csv and ZSCORENormalizedFile.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Justification of using Sckikit-learn's KNearestNeighbors implementation instead of utilizing an implementation of KNearestNeighbors on Spark__\n",
    "\n",
    "\n",
    "* Since the K-Nearest-Neighbours algorithm is not available in Spark as it would be unsuitable for Big Data since the KNN model is practically the entire dataset the model is being used on [reference](https://forums.databricks.com/answers/10558/view.html); I tried using this KNN [implementation](https://github.com/saurfang/spark-knn) on Spark which is available on GitHub. Package installation steps [here](https://spark-packages.org/package/saurfang/spark-knn).\n",
    "\n",
    "    __Unfortunately__, the GitHub repository supports Spark version 2.1.0. I was having \"'JavaPackage' object is not callable\" errors  I have tried installing and running a version 2.1.0 Spark Session in this notebook but it appeared it did not have support for Python 3, so I installed a Python 2 kernel and ended up having the same problem. I have also tried Spark version 2.1.0 to 2.1.3.\n",
    "\n",
    "For reference, the list of commands to download the required packages for the GitHub repository:\n",
    "\n",
    "    ```\n",
    "    !apt-get install -y wget\n",
    "    !apt-get install -y git\n",
    "    !mkdir knn-lib\n",
    "    !git clone https://github.com/saurfang/spark-knn knn-lib/\n",
    "    !cp knn_lib/python/pyspark_knn . -r\n",
    "    !wget http://dl.bintray.com/spark-packages/maven/saurfang/spark-knn/0.3.0/spark-knn-0.3.0.jar\n",
    "    !python knn-lib/python/test.py\n",
    "    !wget https://archive.apache.org/dist/spark/spark-2.1.0/spark-2.1.0-bin-hadoop2.7.tgz\n",
    "    !tar -xf spark-2.1.0-bin-hadoop2.7.tgz\n",
    "    !wget https://archive.apache.org/dist/spark/spark-2.1.1/spark-2.1.1-bin-hadoop2.7.tgz\n",
    "    !tar -xf spark-2.1.1-bin-hadoop2.7.tgz\n",
    "    !wget https://archive.apache.org/dist/spark/spark-2.1.2/spark-2.1.2-bin-hadoop2.7.tgz\n",
    "    !tar -xf spark-2.1.2-bin-hadoop2.7.tgz\n",
    "    !wget https://archive.apache.org/dist/spark/spark-2.1.3/spark-2.1.3-bin-hadoop2.7.tgz\n",
    "    !tar -xf spark-2.1.3-bin-hadoop2.7.tgz\n",
    "    ```\n",
    "\n",
    "For reference, the python code for importing the KNNClassifier implementation:\n",
    "\n",
    "    ```\n",
    "    import os\n",
    "    os.environ[\"SPARK_HOME\"] = \"/opt/workspace/spark-2.1.1-bin-hadoop2.7\"\n",
    "    import findspark\n",
    "    findspark.init(\"/opt/workspace/spark-2.1.1-bin-hadoop2.7\")\n",
    "    from pyspark.sql import SparkSession\n",
    "    from pyspark.sql import functions as F\n",
    "    from pyspark_knn.ml.classification import KNNClassifier\n",
    "\n",
    "    spark_knn = SparkSession.builder.master(\"local[*]\").config(\"spark.jars\", \"spark-knn-0.3.0.jar\").getOrCreate()\n",
    "\n",
    "    model = KNNClassifier()\n",
    "\n",
    "    ```\n",
    "\n",
    "    ```\n",
    "    # Further testing using the test.py script from the GitHub repository:\n",
    "    \n",
    "    from pyspark import SparkContext\n",
    "    from pyspark.sql import SQLContext\n",
    "    from pyspark.mllib.linalg import Vectors\n",
    "    from pyspark_knn.ml.classification import KNNClassifier\n",
    "\n",
    "    # This is a simple test app. Use the following command to run:\n",
    "    # spark-submit --driver-class-path ../spark-knn-core/target/scala-2.11/spark-knn_*.jar test.py\n",
    "\n",
    "    sc = SparkContext(appName='test')\n",
    "    sqlContext = SQLContext(sc)\n",
    "\n",
    "    knn = KNNClassifier(k=1, topTreeSize=1, topTreeLeafSize=1, subTreeLeafSize=1, bufferSizeSampleSize=[1, 2, 3])  # bufferSize=-1.0,    \n",
    "    ```\n",
    "\n",
    "* I have also checked some models in PySpark ML that approximate Nearest Neighbors [link1](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.BucketedRandomProjectionLSHModel.approxNearestNeighbors) [link2](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.MinHashLSHModel.approxNearestNeighbors). __Unfortunately__, to my understanding, they don't act as a classifier for the purposes of the assignment.\n",
    "\n",
    "__As per the reasons stated above and due to the lack of ability to allocate more time to find a way to make KNearestNeighbors work on Spark; I have decided to utilize the scikit-learn implementation of the algorithm.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __4.1 Reading spark dataframes as pandas dataframes__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   A       768 non-null    int32  \n",
      " 1   B       768 non-null    int32  \n",
      " 2   C       768 non-null    int32  \n",
      " 3   D       768 non-null    int32  \n",
      " 4   E       768 non-null    int32  \n",
      " 5   F       768 non-null    float64\n",
      " 6   G       768 non-null    float64\n",
      " 7   H       768 non-null    int32  \n",
      " 8   Class   768 non-null    object \n",
      "dtypes: float64(2), int32(6), object(1)\n",
      "memory usage: 36.1+ KB\n"
     ]
    }
   ],
   "source": [
    "pandas_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A    B   C   D    E     F      G   H            Class\n",
       "0  6  148  72  35    0  33.6  0.627  50  tested_positive\n",
       "1  1   85  66  29    0  26.6  0.351  31  tested_negative\n",
       "2  8  183  64   0    0  23.3  0.672  32  tested_positive\n",
       "3  1   89  66  23   94  28.1  0.167  21  tested_negative\n",
       "4  0  137  40  35  168  43.1  2.288  33  tested_positive"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __4.2 One-hot encoding the class column__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = pd.get_dummies(data=pandas_df, columns=['Class'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>Class_tested_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A    B   C   D    E     F      G   H  Class_tested_positive\n",
       "0  6  148  72  35    0  33.6  0.627  50                      1\n",
       "1  1   85  66  29    0  26.6  0.351  31                      0\n",
       "2  8  183  64   0    0  23.3  0.672  32                      1\n",
       "3  1   89  66  23   94  28.1  0.167  21                      0\n",
       "4  0  137  40  35  168  43.1  2.288  33                      1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __4.3 Splitting into training and test sets__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 420  # For reproduciblility\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    pandas_df,\n",
    "    train_size=0.75,\n",
    "    test_size=0.25,\n",
    "    random_state=seed,  # For reproduciblility\n",
    "    shuffle=False  # No random shuffling before splitting\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 576 entries, 0 to 575\n",
      "Data columns (total 9 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   A                      576 non-null    int32  \n",
      " 1   B                      576 non-null    int32  \n",
      " 2   C                      576 non-null    int32  \n",
      " 3   D                      576 non-null    int32  \n",
      " 4   E                      576 non-null    int32  \n",
      " 5   F                      576 non-null    float64\n",
      " 6   G                      576 non-null    float64\n",
      " 7   H                      576 non-null    int32  \n",
      " 8   Class_tested_positive  576 non-null    uint8  \n",
      "dtypes: float64(2), int32(6), uint8(1)\n",
      "memory usage: 27.6 KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>Class_tested_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A    B   C   D    E     F      G   H  Class_tested_positive\n",
       "0  6  148  72  35    0  33.6  0.627  50                      1\n",
       "1  1   85  66  29    0  26.6  0.351  31                      0\n",
       "2  8  183  64   0    0  23.3  0.672  32                      1\n",
       "3  1   89  66  23   94  28.1  0.167  21                      0\n",
       "4  0  137  40  35  168  43.1  2.288  33                      1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 192 entries, 576 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   A                      192 non-null    int32  \n",
      " 1   B                      192 non-null    int32  \n",
      " 2   C                      192 non-null    int32  \n",
      " 3   D                      192 non-null    int32  \n",
      " 4   E                      192 non-null    int32  \n",
      " 5   F                      192 non-null    float64\n",
      " 6   G                      192 non-null    float64\n",
      " 7   H                      192 non-null    int32  \n",
      " 8   Class_tested_positive  192 non-null    uint8  \n",
      "dtypes: float64(2), int32(6), uint8(1)\n",
      "memory usage: 9.2 KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>Class_tested_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>6</td>\n",
       "      <td>108</td>\n",
       "      <td>44</td>\n",
       "      <td>20</td>\n",
       "      <td>130</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.813</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>2</td>\n",
       "      <td>118</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42.9</td>\n",
       "      <td>0.693</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>10</td>\n",
       "      <td>133</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.245</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>34.7</td>\n",
       "      <td>0.575</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>90</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>42.1</td>\n",
       "      <td>0.371</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A    B   C   D    E     F      G   H  Class_tested_positive\n",
       "576   6  108  44  20  130  24.0  0.813  35                      0\n",
       "577   2  118  80   0    0  42.9  0.693  21                      1\n",
       "578  10  133  68   0    0  27.0  0.245  36                      0\n",
       "579   2  197  70  99    0  34.7  0.575  62                      1\n",
       "580   0  151  90  46    0  42.1  0.371  21                      1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __4.4 Applying Min-Max and ZSCORE scaling to the train and test sets, I have decided to apply scaling after splitting to make sure the train and test sets are the same for both scaling methods__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "minmax_scaler = MinMaxScaler()\n",
    "standard_scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "\n",
    "columns = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __4.4.1 Min-Max scaling__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Was having issues when not using deep copies, the scaling transformation would\n",
    "#  affect the original train_df and test_df if deep copying is not specified\n",
    "minmax_train_df = train_df.copy(deep=True)\n",
    "minmax_test_df = test_df.copy(deep=True)\n",
    "\n",
    "minmax_train_df[columns] = minmax_scaler.fit_transform(minmax_train_df[columns])\n",
    "minmax_test_df[columns] = minmax_scaler.fit_transform(minmax_test_df[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 576 entries, 0 to 575\n",
      "Data columns (total 9 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   A                      576 non-null    float64\n",
      " 1   B                      576 non-null    float64\n",
      " 2   C                      576 non-null    float64\n",
      " 3   D                      576 non-null    float64\n",
      " 4   E                      576 non-null    float64\n",
      " 5   F                      576 non-null    float64\n",
      " 6   G                      576 non-null    float64\n",
      " 7   H                      576 non-null    float64\n",
      " 8   Class_tested_positive  576 non-null    uint8  \n",
      "dtypes: float64(8), uint8(1)\n",
      "memory usage: 41.1 KB\n"
     ]
    }
   ],
   "source": [
    "minmax_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>Class_tested_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.747475</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500745</td>\n",
       "      <td>0.234415</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.429293</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.460317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396423</td>\n",
       "      <td>0.116567</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.924242</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347243</td>\n",
       "      <td>0.253629</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.449495</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.365079</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.418778</td>\n",
       "      <td>0.038002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.691919</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.198582</td>\n",
       "      <td>0.642325</td>\n",
       "      <td>0.943638</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D         E         F         G  \\\n",
       "0  0.352941  0.747475  0.590164  0.555556  0.000000  0.500745  0.234415   \n",
       "1  0.058824  0.429293  0.540984  0.460317  0.000000  0.396423  0.116567   \n",
       "2  0.470588  0.924242  0.524590  0.000000  0.000000  0.347243  0.253629   \n",
       "3  0.058824  0.449495  0.540984  0.365079  0.111111  0.418778  0.038002   \n",
       "4  0.000000  0.691919  0.327869  0.555556  0.198582  0.642325  0.943638   \n",
       "\n",
       "          H  Class_tested_positive  \n",
       "0  0.483333                      1  \n",
       "1  0.166667                      0  \n",
       "2  0.183333                      1  \n",
       "3  0.000000                      0  \n",
       "4  0.200000                      1  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 192 entries, 576 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   A                      192 non-null    float64\n",
      " 1   B                      192 non-null    float64\n",
      " 2   C                      192 non-null    float64\n",
      " 3   D                      192 non-null    float64\n",
      " 4   E                      192 non-null    float64\n",
      " 5   F                      192 non-null    float64\n",
      " 6   G                      192 non-null    float64\n",
      " 7   H                      192 non-null    float64\n",
      " 8   Class_tested_positive  192 non-null    uint8  \n",
      "dtypes: float64(8), uint8(1)\n",
      "memory usage: 13.7 KB\n"
     ]
    }
   ],
   "source": [
    "minmax_test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>Class_tested_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.202020</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.418848</td>\n",
       "      <td>0.450031</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.433566</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.748691</td>\n",
       "      <td>0.375543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.471204</td>\n",
       "      <td>0.097455</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.986014</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.605585</td>\n",
       "      <td>0.302297</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.664336</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.464646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.734729</td>\n",
       "      <td>0.175667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            A         B         C         D         E         F         G  \\\n",
       "576  0.461538  0.363636  0.385965  0.202020  0.216667  0.418848  0.450031   \n",
       "577  0.153846  0.433566  0.701754  0.000000  0.000000  0.748691  0.375543   \n",
       "578  0.769231  0.538462  0.596491  0.000000  0.000000  0.471204  0.097455   \n",
       "579  0.153846  0.986014  0.614035  1.000000  0.000000  0.605585  0.302297   \n",
       "580  0.000000  0.664336  0.789474  0.464646  0.000000  0.734729  0.175667   \n",
       "\n",
       "            H  Class_tested_positive  \n",
       "576  0.285714                      0  \n",
       "577  0.000000                      1  \n",
       "578  0.306122                      0  \n",
       "579  0.836735                      1  \n",
       "580  0.000000                      1  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __4.4.2 ZSCORE scaling__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Was having issues when not using deep copies, the scaling transformation would\n",
    "#  affect the original train_df and test_df if deep copying is not specified\n",
    "standard_train_df = train_df.copy(deep=True)\n",
    "standard_test_df = test_df.copy(deep=True)\n",
    "\n",
    "standard_train_df[columns] = standard_scaler.fit_transform(standard_train_df[columns])\n",
    "standard_test_df[columns] = standard_scaler.fit_transform(standard_test_df[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 576 entries, 0 to 575\n",
      "Data columns (total 9 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   A                      576 non-null    float64\n",
      " 1   B                      576 non-null    float64\n",
      " 2   C                      576 non-null    float64\n",
      " 3   D                      576 non-null    float64\n",
      " 4   E                      576 non-null    float64\n",
      " 5   F                      576 non-null    float64\n",
      " 6   G                      576 non-null    float64\n",
      " 7   H                      576 non-null    float64\n",
      " 8   Class_tested_positive  576 non-null    uint8  \n",
      "dtypes: float64(8), uint8(1)\n",
      "memory usage: 41.1 KB\n"
     ]
    }
   ],
   "source": [
    "standard_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>Class_tested_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.655888</td>\n",
       "      <td>0.858193</td>\n",
       "      <td>0.165672</td>\n",
       "      <td>0.922316</td>\n",
       "      <td>-0.690469</td>\n",
       "      <td>0.212803</td>\n",
       "      <td>0.438215</td>\n",
       "      <td>1.429049</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.839724</td>\n",
       "      <td>-1.075860</td>\n",
       "      <td>-0.145672</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>-0.690469</td>\n",
       "      <td>-0.659347</td>\n",
       "      <td>-0.384206</td>\n",
       "      <td>-0.185769</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.254133</td>\n",
       "      <td>1.932667</td>\n",
       "      <td>-0.249454</td>\n",
       "      <td>-1.316832</td>\n",
       "      <td>-0.690469</td>\n",
       "      <td>-1.070503</td>\n",
       "      <td>0.572305</td>\n",
       "      <td>-0.100779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.839724</td>\n",
       "      <td>-0.953063</td>\n",
       "      <td>-0.145672</td>\n",
       "      <td>0.154608</td>\n",
       "      <td>0.121960</td>\n",
       "      <td>-0.472458</td>\n",
       "      <td>-0.932487</td>\n",
       "      <td>-1.035673</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.138846</td>\n",
       "      <td>0.520502</td>\n",
       "      <td>-1.494832</td>\n",
       "      <td>0.922316</td>\n",
       "      <td>0.761532</td>\n",
       "      <td>1.396435</td>\n",
       "      <td>5.387642</td>\n",
       "      <td>-0.015788</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D         E         F         G  \\\n",
       "0  0.655888  0.858193  0.165672  0.922316 -0.690469  0.212803  0.438215   \n",
       "1 -0.839724 -1.075860 -0.145672  0.538462 -0.690469 -0.659347 -0.384206   \n",
       "2  1.254133  1.932667 -0.249454 -1.316832 -0.690469 -1.070503  0.572305   \n",
       "3 -0.839724 -0.953063 -0.145672  0.154608  0.121960 -0.472458 -0.932487   \n",
       "4 -1.138846  0.520502 -1.494832  0.922316  0.761532  1.396435  5.387642   \n",
       "\n",
       "          H  Class_tested_positive  \n",
       "0  1.429049                      1  \n",
       "1 -0.185769                      0  \n",
       "2 -0.100779                      1  \n",
       "3 -1.035673                      0  \n",
       "4 -0.015788                      1  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 192 entries, 576 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   A                      192 non-null    float64\n",
      " 1   B                      192 non-null    float64\n",
      " 2   C                      192 non-null    float64\n",
      " 3   D                      192 non-null    float64\n",
      " 4   E                      192 non-null    float64\n",
      " 5   F                      192 non-null    float64\n",
      " 6   G                      192 non-null    float64\n",
      " 7   H                      192 non-null    float64\n",
      " 8   Class_tested_positive  192 non-null    uint8  \n",
      "dtypes: float64(8), uint8(1)\n",
      "memory usage: 13.7 KB\n"
     ]
    }
   ],
   "source": [
    "standard_test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>Class_tested_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>0.594081</td>\n",
       "      <td>-0.517118</td>\n",
       "      <td>-1.331274</td>\n",
       "      <td>-0.023507</td>\n",
       "      <td>0.444451</td>\n",
       "      <td>-1.119032</td>\n",
       "      <td>1.155826</td>\n",
       "      <td>0.136095</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>-0.569833</td>\n",
       "      <td>-0.182256</td>\n",
       "      <td>0.512029</td>\n",
       "      <td>-1.211204</td>\n",
       "      <td>-0.700388</td>\n",
       "      <td>1.430885</td>\n",
       "      <td>0.776148</td>\n",
       "      <td>-1.059408</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>1.757996</td>\n",
       "      <td>0.320038</td>\n",
       "      <td>-0.102406</td>\n",
       "      <td>-1.211204</td>\n",
       "      <td>-0.700388</td>\n",
       "      <td>-0.714283</td>\n",
       "      <td>-0.641316</td>\n",
       "      <td>0.221488</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>-0.569833</td>\n",
       "      <td>2.463158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.667900</td>\n",
       "      <td>-0.700388</td>\n",
       "      <td>0.324572</td>\n",
       "      <td>0.402798</td>\n",
       "      <td>2.441708</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>-1.151790</td>\n",
       "      <td>0.922790</td>\n",
       "      <td>1.024057</td>\n",
       "      <td>1.520501</td>\n",
       "      <td>-0.700388</td>\n",
       "      <td>1.322952</td>\n",
       "      <td>-0.242654</td>\n",
       "      <td>-1.059408</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            A         B         C         D         E         F         G  \\\n",
       "576  0.594081 -0.517118 -1.331274 -0.023507  0.444451 -1.119032  1.155826   \n",
       "577 -0.569833 -0.182256  0.512029 -1.211204 -0.700388  1.430885  0.776148   \n",
       "578  1.757996  0.320038 -0.102406 -1.211204 -0.700388 -0.714283 -0.641316   \n",
       "579 -0.569833  2.463158  0.000000  4.667900 -0.700388  0.324572  0.402798   \n",
       "580 -1.151790  0.922790  1.024057  1.520501 -0.700388  1.322952 -0.242654   \n",
       "\n",
       "            H  Class_tested_positive  \n",
       "576  0.136095                      0  \n",
       "577 -1.059408                      1  \n",
       "578  0.221488                      0  \n",
       "579  2.441708                      1  \n",
       "580 -1.059408                      1  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __4.5 Training on KNearestNeighbors with a set number of 7 neighbors on both min-max and zscore scaled data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import  accuracy_score, classification_report\n",
    "\n",
    "X_columns = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n",
    "y_column = ['Class_tested_positive']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __4.5.1 min-max scaled data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_minmax = KNeighborsClassifier(\n",
    "    n_neighbors=7,\n",
    "    algorithm='auto',\n",
    "    weights='uniform',\n",
    "    n_jobs=-1  # use all available cpu cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_jobs=-1, n_neighbors=7)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Added .values.ravel() to y-column as there was a warning by scikit-learn with the following message:\n",
    "#  DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
    "KNN_minmax.fit(X=minmax_train_df[X_columns], y=minmax_train_df[y_column].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_minmax = KNN_minmax.predict(X=minmax_test_df[X_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score = 76.04166666666666%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_true=minmax_test_df[y_column].values.ravel(), y_pred=y_pred_minmax) * 100\n",
    "print(f'Accuracy score = {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7533    0.9262    0.8309       122\n",
      "           1     0.7857    0.4714    0.5893        70\n",
      "\n",
      "    accuracy                         0.7604       192\n",
      "   macro avg     0.7695    0.6988    0.7101       192\n",
      "weighted avg     0.7651    0.7604    0.7428       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=minmax_test_df[y_column].values.ravel(), y_pred=y_pred_minmax, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __4.5.2 zscore scaled data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_standard = KNeighborsClassifier(\n",
    "    n_neighbors=7,\n",
    "    algorithm='auto',\n",
    "    weights='uniform',\n",
    "    n_jobs=-1  # use all available cpu cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_jobs=-1, n_neighbors=7)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Added .values.ravel() to y-column as there was a warning by scikit-learn with the following message:\n",
    "#  DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
    "KNN_standard.fit(X=standard_train_df[X_columns], y=standard_train_df[y_column].values.ravel()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_standard = KNN_standard.predict(X=standard_test_df[X_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score = 75.0%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_true=standard_test_df[y_column].values.ravel(), y_pred=y_pred_standard) * 100\n",
    "print(f'Accuracy score = {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7681    0.8689    0.8154       122\n",
      "           1     0.7037    0.5429    0.6129        70\n",
      "\n",
      "    accuracy                         0.7500       192\n",
      "   macro avg     0.7359    0.7059    0.7141       192\n",
      "weighted avg     0.7446    0.7500    0.7416       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=standard_test_df[y_column].values.ravel(), y_pred=y_pred_standard, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Q4. Answer__:\n",
    "When setting the number of neighbours parameter for the KNN model to __7__; __the KNN model that was trained on min-max scaled data outperforms the KNN model trained on zscore scaled data__.\n",
    "\n",
    "However, while experimenting with other values for the number of neighbours parameter, it appears that the __KNN model trained on the zscore scaled data generally tends to outperform the KNN model trained on the min-max scaled data__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BD_Assignment2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
