{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Copy of Spark_linalg_FeatureEng.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmIDnTMWSJT5"
      },
      "source": [
        "# Setup Spark environment "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7-agJILRFIP",
        "outputId": "934abcce-62d8-40e7-bd18-9ca631095698"
      },
      "source": [
        "import time\n",
        "import os\n",
        "\n",
        "Start=time.time()\n",
        "# Download and install tools \n",
        "\n",
        "# Install Java\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Download and Install Spark\n",
        "!wget  -q http://apache.osuosl.org/spark/spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.7-bin-hadoop2.7.tgz\n",
        "\n",
        "# Install findspark\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set environment variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.7-bin-hadoop2.7\"\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "print(f\"\\nIt took {(time.time()-Start)} seconds to install all dependencies for spark to run on Google Colab. \\n\")\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "It took 49.65678119659424 seconds to install all dependencies for spark to run on Google Colab. \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fczzqs7GjzrM"
      },
      "source": [
        "# Vectors and Matrices "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKr_nlnNTB74"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1V8XppjXTB7-"
      },
      "source": [
        "API Guide: https://spark.apache.org/docs/2.4.7/api/python/pyspark.ml.html#module-pyspark.ml.linalg\n",
        "\n",
        "MLlib utilities for linear algebra.  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpdLpvq9TB7_"
      },
      "source": [
        "## Vectors\n",
        "For dense vectors, MLlib uses the __NumPy array__ type, so you can simply pass NumPy arrays around.  \n",
        "For sparse vectors, you can construct a SparseVector object from MLlib or pass SciPy __scipy.sparse__ column vectors if __SciPy__ is available in the environment.\n",
        "\n",
        "Docs (RDD-section): https://spark.apache.org/docs/latest/mllib-data-types.html#local-vector  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeqNqGidTB7_"
      },
      "source": [
        "## Sparse Vector Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk8BqF50pIRw"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhOvCbYTTB8A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0401fbde-4250-4252-cf32-2e8b9d4f45ba"
      },
      "source": [
        "import numpy as np\n",
        "from pyspark.ml.linalg import Vectors\n",
        "\n",
        "# Create a SparseVector.\n",
        "sv1 = Vectors.sparse(7, [0, 6], [1.0, 3.0])\n",
        "\n",
        "print(sv1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7,[0,6],[1.0,3.0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5NHYK3ATB8C"
      },
      "source": [
        "### Matrices\n",
        "\n",
        "Docs (RDD-section): https://spark.apache.org/docs/latest/mllib-data-types.html#local-matrix\n",
        "\n",
        "> The base class of local matrices is _Matrix_, and we provide two implementations: _DenseMatrix_, and _SparseMatrix_. We recommend using the factory methods implemented in _Matrices_ to create local matrices. Remember, local matrices in MLlib are stored in column-major order.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH38En5xTB8C"
      },
      "source": [
        "## Dense Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--gFAwYkTB8C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed714b0e-0e5d-45c1-a421-d03411a750f1"
      },
      "source": [
        "from pyspark.ml.linalg import Matrices\n",
        "\n",
        "# Create a dense matrix ((1.0, 2.0), (3.0, 4.0), (5.0, 6.0))\n",
        "dm2 = Matrices.dense(3, 2, [1, 3, 5, 2, 4, 6])\n",
        "print(dm2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DenseMatrix([[1., 2.],\n",
            "             [3., 4.],\n",
            "             [5., 6.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4sl2W6eTB8D"
      },
      "source": [
        "## Sparse Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5NsdDqrTB8D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13350147-2a92-44eb-9e59-b4f2b14ddaa6"
      },
      "source": [
        "# Create a sparse matrix ((9.0, 0.0), (0.0, 8.0), (0.0, 6.0))\n",
        "sm = Matrices.sparse(3, 2, [0, 1, 3], [0, 2, 1], [9, 6, 8])\n",
        "print(sm)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 X 2 CSCMatrix\n",
            "(0,0) 9.0\n",
            "(2,1) 6.0\n",
            "(1,1) 8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxWKfQAPdWxP"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpcv_whornEd",
        "outputId": "60b71a50-69a2-476c-c7bf-fd08588364ef"
      },
      "source": [
        "from pyspark.ml.feature import MinMaxScaler\n",
        "from pyspark.ml.linalg import Vectors\n",
        "\n",
        "dataFrame = spark.createDataFrame([\n",
        "    (0, Vectors.dense([1.0, 0.1, -1.0]),),\n",
        "    (1, Vectors.dense([2.0, 1.1, 1.0]),),\n",
        "    (2, Vectors.dense([3.0, 10.1, 3.0]),)\n",
        "], [\"id\", \"features\"])\n",
        "\n",
        "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
        "\n",
        "# Compute summary statistics and generate MinMaxScalerModel\n",
        "scalerModel = scaler.fit(dataFrame)\n",
        "\n",
        "# rescale each feature to range [min, max].\n",
        "scaledData = scalerModel.transform(dataFrame)\n",
        "print(\"Features scaled to range: [%f, %f]\" % (scaler.getMin(), scaler.getMax()))\n",
        "scaledData.select(\"features\", \"scaledFeatures\").show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features scaled to range: [0.000000, 1.000000]\n",
            "+--------------+--------------+\n",
            "|      features|scaledFeatures|\n",
            "+--------------+--------------+\n",
            "|[1.0,0.1,-1.0]| [0.0,0.0,0.0]|\n",
            "| [2.0,1.1,1.0]| [0.5,0.1,0.5]|\n",
            "|[3.0,10.1,3.0]| [1.0,1.0,1.0]|\n",
            "+--------------+--------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u99PhTmQvscd"
      },
      "source": [
        "Features\n",
        "---\n",
        "MLlib Main Guide: https://spark.apache.org/docs/2.4.7/ml-features.html\n",
        "\n",
        "This module contains algorithms for working with features, roughly divided into these groups:\n",
        "\n",
        "- Extraction: Extracting features from “raw” data\n",
        "- Transformation: Scaling, converting, or modifying features\n",
        "- Selection: Selecting a subset from a larger set of features\n",
        "- Locality Sensitive Hashing (LSH): This class of algorithms combines aspects of feature transformation with other algorithms.\n",
        "\n",
        "## pyspark.ml.feature\n",
        "Class structure: https://spark.apache.org/docs/2.4.7/api/python/pyspark.ml.html#module-pyspark.ml.feature  \n",
        "GitHub: https://github.com/apache/spark/blob/v2.4.7/python/pyspark/ml/feature.py\n",
        "\n",
        "### [Feature Extractors](https://spark.apache.org/docs/2.4.7/ml-features.html#feature-extractors)\n",
        "\n",
        "- [HashingTF](https://spark.apache.org/docs/2.4.3/ml-features.html#tf-idf)\n",
        "- [IDF & IDFModel](https://spark.apache.org/docs/2.4.3/ml-features.html#tf-idf)\n",
        "- [Word2Vec & Word2VecModel](https://spark.apache.org/docs/2.4.3/ml-features.html#word2vec)\n",
        "- [CountVectorizer & CountVectorizerModel](https://spark.apache.org/docs/2.4.3/ml-features.html#countvectorizer)\n",
        "- [FeatureHasher](https://spark.apache.org/docs/2.4.3/ml-features.html#featurehasher)\n",
        "\n",
        "\n",
        "### [Feature Transformers](https://spark.apache.org/docs/2.4.3/ml-features.html#feature-transformers)\n",
        "\n",
        "- [Tokenizer](https://spark.apache.org/docs/2.4.3/ml-features.html#tokenizer)\n",
        "- [RegexTokenizer](https://spark.apache.org/docs/2.4.3/ml-features.html#tokenizer)\n",
        "- [StopWordsRemover](https://spark.apache.org/docs/2.4.3/ml-features.html#stopwordsremover)\n",
        "- [NGram](https://spark.apache.org/docs/2.4.3/ml-features.html#n-gram)\n",
        "- [Binarizer](https://spark.apache.org/docs/2.4.3/ml-features.html#binarizer)\n",
        "- [PCA](https://spark.apache.org/docs/2.4.3/ml-features.html#pca)\n",
        "- [PCAModel](https://spark.apache.org/docs/2.4.3/ml-features.html#pca)\n",
        "- [PolynomialExpansion](https://spark.apache.org/docs/2.4.3/ml-features.html#polynomialexpansion)\n",
        "- [DCT](https://spark.apache.org/docs/2.4.3/ml-features.html#discrete-cosine-transform-dct)\n",
        "- [StringIndexer & StringIndexerModel](https://spark.apache.org/docs/2.4.3/ml-features.html#stringindexer)\n",
        "- [IndexToString](https://spark.apache.org/docs/2.4.3/ml-features.html#indextostring)\n",
        "- [OneHotEncoder & OneHotEncoderModel](https://spark.apache.org/docs/2.4.3/ml-features.html#onehotencoder-deprecated-since-230)\n",
        "- [OneHotEncoderEstimator](https://spark.apache.org/docs/2.4.3/ml-features.html#onehotencoderestimator)\n",
        "- [VectorIndexer](https://spark.apache.org/docs/2.4.3/ml-features.html#vectorindexer)\n",
        "- [VectorIndexerModel](https://spark.apache.org/docs/2.4.3/ml-features.html#vectorindexer)\n",
        "- [Normalizer](https://spark.apache.org/docs/2.4.3/ml-features.html#normalizer)\n",
        "- [StandardScaler & StandardScalerModel](https://spark.apache.org/docs/2.4.3/ml-features.html#standardscaler)\n",
        "- [MinMaxScaler & MinMaxScalerModel](https://spark.apache.org/docs/2.4.3/ml-features.html#minmaxscaler)\n",
        "- [MaxAbsScaler & MaxAbsScalerModel](https://spark.apache.org/docs/2.4.3/ml-features.html#maxabsscaler)\n",
        "- [Bucketizer](https://spark.apache.org/docs/2.4.3/ml-features.html#bucketizer)\n",
        "- [ElementwiseProduct](https://spark.apache.org/docs/2.4.3/ml-features.html#elementwiseproduct)\n",
        "- [SQLTransformer](https://spark.apache.org/docs/2.4.3/ml-features.html#sqltransformer)\n",
        "- [VectorAssembler](https://spark.apache.org/docs/2.4.3/ml-features.html#vectorassembler)\n",
        "- [VectorSizeHint](https://spark.apache.org/docs/2.4.3/ml-features.html#vectorsizehint)\n",
        "- [QuantileDiscretizer](https://spark.apache.org/docs/2.4.3/ml-features.html#quantilediscretizer)\n",
        "- [Imputer & ImputerModel](https://spark.apache.org/docs/2.4.3/ml-features.html#imputer)\n",
        "\n",
        "Not available in Python:\n",
        "- [Interaction](https://spark.apache.org/docs/2.4.3/ml-features.html#interaction)\n",
        "\n",
        "## [Feature Selectors](https://spark.apache.org/docs/2.4.3/ml-features.html#feature-selectors)\n",
        "\n",
        "- [VectorSlicer](https://spark.apache.org/docs/2.4.3/ml-features.html#vectorslicer)\n",
        "- [RFormula & RFormulaModel](https://spark.apache.org/docs/2.4.3/ml-features.html#rformula)\n",
        "- [ChiSqSelector & ChiSqSelectorModel](https://spark.apache.org/docs/2.4.3/ml-features.html#chisqselector)\n",
        "\n",
        "\n",
        "## [Locality Sensitive Hashing (LSH)](https://spark.apache.org/docs/2.4.3/ml-features.html#locality-sensitive-hashing)\n",
        "\n",
        "- [BucketedRandomProjectionLSH & BucketedRandomProjectionLSHModel](https://spark.apache.org/docs/2.4.3/ml-features.html#bucketed-random-projection-for-euclidean-distance)\n",
        "- [MinHashLSH & MinHashLSHModel](https://spark.apache.org/docs/2.4.3/ml-features.html#minhash-for-jaccard-distance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WZDZNlzeUzT"
      },
      "source": [
        "--------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnK_DMNedbLG"
      },
      "source": [
        "## QuantileDiscretizer\n",
        "\n",
        "- [Link](https://spark.apache.org/docs/2.4.3/ml-features.html#quantilediscretizer)\n",
        "\n",
        "QuantileDiscretizer takes a column with continuous features and outputs a column with binned categorical features. The number of bins is set by the numBuckets parameter. It is possible that the number of buckets used will be smaller than this value, for example, if there are too few distinct values of the input to create enough distinct quantiles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9IX52OJvscl"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDl6JMSJvscm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac03a61f-62d3-4993-90af-1b3a962aa92c"
      },
      "source": [
        "from pyspark.ml.feature import QuantileDiscretizer\n",
        "\n",
        "data = [(0, 18.0), (1, 19.0), (2, 8.0), (3, 5.0), (4, 2.2),(5,10.0)]\n",
        "df = spark.createDataFrame(data, [\"id\", \"hour\"])\n",
        "\n",
        "discretizer = QuantileDiscretizer(numBuckets=3, inputCol=\"hour\", outputCol=\"result\")\n",
        "\n",
        "result = discretizer.fit(df).transform(df)\n",
        "result.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+----+------+\n",
            "| id|hour|result|\n",
            "+---+----+------+\n",
            "|  0|18.0|   2.0|\n",
            "|  1|19.0|   2.0|\n",
            "|  2| 8.0|   1.0|\n",
            "|  3| 5.0|   1.0|\n",
            "|  4| 2.2|   0.0|\n",
            "|  5|10.0|   2.0|\n",
            "+---+----+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk9-RPfkh84y"
      },
      "source": [
        "## Word2Vec\n",
        "\n",
        "Word2Vec is an Estimator which takes sequences of words representing documents and trains a Word2VecModel. The model maps each word to a unique fixed-size vector. The Word2VecModel transforms each document into a vector using the average of all words in the document; this vector can then be used as features for prediction, document similarity calculations, etc. \n",
        "\n",
        "[Link](https://spark.apache.org/docs/2.4.3/ml-features.html#word2vec)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spmyaW01vscn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09c19c5c-c5a4-4c62-ce80-c66856436f0f"
      },
      "source": [
        "from pyspark.ml.feature import Word2Vec\n",
        "\n",
        "# Input data: Each row is a bag of words from a sentence or document.\n",
        "documentDF = spark.createDataFrame(\n",
        "    [\n",
        "        (\"Hi I heard about Spark\".split(\" \"),),\n",
        "        (\"I wish Java could use case classes\".split(\" \"),),\n",
        "        (\"Logistic regression models are neat\".split(\" \"),),\n",
        "    ],\n",
        "    [\"text\"],\n",
        ")\n",
        "\n",
        "# Learn a mapping from words to Vectors.\n",
        "word2Vec = Word2Vec(vectorSize=3, minCount=0, inputCol=\"text\", outputCol=\"result\")\n",
        "model = word2Vec.fit(documentDF)\n",
        "\n",
        "result = model.transform(documentDF)\n",
        "for row in result.collect():\n",
        "    text, vector = row\n",
        "    print(f\"Text: {text} => \\nVector: {vector}\\n\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text: ['Hi', 'I', 'heard', 'about', 'Spark'] => \n",
            "Vector: [0.035423544165678326,0.0079280111938715,-0.021331259980797768]\n",
            "\n",
            "Text: ['I', 'wish', 'Java', 'could', 'use', 'case', 'classes'] => \n",
            "Vector: [-0.02603385703904288,-0.0041177283440317425,-0.01595430581697396]\n",
            "\n",
            "Text: ['Logistic', 'regression', 'models', 'are', 'neat'] => \n",
            "Vector: [-0.08101594150066377,0.05188082894310356,0.03756050691008568]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBiNv08kjG5o"
      },
      "source": [
        "## StringIndexer\n",
        "\n",
        "StringIndexer encodes a string column of labels to a column of label indices.  \n",
        "\n",
        "[Link](https://spark.apache.org/docs/2.4.3/ml-features.html#StringIndexer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja4cmODQvscp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1ead213-c50a-4ffc-f0f7-d45d6a8b2480"
      },
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "df = spark.createDataFrame(\n",
        "    [\n",
        "        (0, \"a\"),\n",
        "        (1, \"b\"),\n",
        "        (2, \"c\"),\n",
        "        (3, \"a\"),\n",
        "        (4, \"a\"),\n",
        "        (5, \"c\"),\n",
        "        (6, \"d\"),\n",
        "        (7, \"a\"),\n",
        "        (8, \"d\"),\n",
        "    ],\n",
        "    [\"id\", \"category\"],\n",
        ")\n",
        "\n",
        "indexer = StringIndexer(inputCol=\"category\", outputCol=\"categoryIndex\")\n",
        "indexed = indexer.fit(df).transform(df)\n",
        "indexed.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------+-------------+\n",
            "| id|category|categoryIndex|\n",
            "+---+--------+-------------+\n",
            "|  0|       a|          0.0|\n",
            "|  1|       b|          3.0|\n",
            "|  2|       c|          2.0|\n",
            "|  3|       a|          0.0|\n",
            "|  4|       a|          0.0|\n",
            "|  5|       c|          2.0|\n",
            "|  6|       d|          1.0|\n",
            "|  7|       a|          0.0|\n",
            "|  8|       d|          1.0|\n",
            "+---+--------+-------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7rce84sj-jV"
      },
      "source": [
        "## FeatureHasher\n",
        "\n",
        "Feature hashing projects a set of categorical or numerical features into a feature vector of specified dimension (typically substantially smaller than that of the original feature space). This is done using the hashing trick to map features to indices in the feature vector. \n",
        "\n",
        "[Link](https://spark.apache.org/docs/2.4.3/ml-features.html#featurehasher)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMjzBSh4vsco",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f6ef7f5-4901-42f4-a4cd-69fa225a9c9f"
      },
      "source": [
        "from pyspark.ml.feature import FeatureHasher\n",
        "\n",
        "dataset = spark.createDataFrame(\n",
        "    [\n",
        "        (2.2, True, \"1\", \"foo\"),\n",
        "        (3.3, False, \"2\", \"bar\"),\n",
        "        (4.4, False, \"3\", \"baz\"),\n",
        "        (5.5, False, \"4\", \"foo\"),\n",
        "    ],\n",
        "    [\"real\", \"bool\", \"stringNum\", \"string\"],\n",
        ")\n",
        "\n",
        "hasher = FeatureHasher(\n",
        "    inputCols=[\"real\", \"bool\", \"stringNum\", \"string\"], outputCol=\"features\"\n",
        ")\n",
        "\n",
        "featurized = hasher.transform(dataset)\n",
        "featurized.show(truncate=False)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+-----+---------+------+--------------------------------------------------------+\n",
            "|real|bool |stringNum|string|features                                                |\n",
            "+----+-----+---------+------+--------------------------------------------------------+\n",
            "|2.2 |true |1        |foo   |(262144,[174475,247670,257907,262126],[2.2,1.0,1.0,1.0])|\n",
            "|3.3 |false|2        |bar   |(262144,[70644,89673,173866,174475],[1.0,1.0,1.0,3.3])  |\n",
            "|4.4 |false|3        |baz   |(262144,[22406,70644,174475,187923],[1.0,1.0,4.4,1.0])  |\n",
            "|5.5 |false|4        |foo   |(262144,[70644,101499,174475,257907],[1.0,1.0,5.5,1.0]) |\n",
            "+----+-----+---------+------+--------------------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5uFHDqRlSTd"
      },
      "source": [
        "## VectorIndexer\n",
        "\n",
        "VectorIndexer helps index categorical features in datasets of Vectors. It can both automatically decide which features are categorical and convert original values to category indices. \n",
        "\n",
        "[Link](https://spark.apache.org/docs/2.4.7/ml-features.html#vectorindexer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-Zr6ci6vscp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8c5825d-8706-4124-91f9-da7e14ae8f24"
      },
      "source": [
        "\n",
        "from pyspark.ml.feature import VectorIndexer\n",
        "\n",
        "data = spark.read.format(\"libsvm\").load(\n",
        "    \"/content/spark-2.4.7-bin-hadoop2.7/data/mllib/sample_libsvm_data.txt\"\n",
        ")\n",
        "\n",
        "indexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexed\", maxCategories=10)\n",
        "indexerModel = indexer.fit(data)\n",
        "\n",
        "categoricalFeatures = indexerModel.categoryMaps\n",
        "print(\n",
        "    f\"Chose {len(categoricalFeatures)} categorical \"\n",
        "    f\"features: {[str(k) for k in categoricalFeatures.keys()]}\"\n",
        ")\n",
        "\n",
        "# Create new column \"indexed\" with categorical values transformed to indices\n",
        "indexedData = indexerModel.transform(data)\n",
        "indexedData.show(truncate=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chose 351 categorical features: ['645', '69', '365', '138', '101', '479', '333', '249', '0', '555', '666', '88', '170', '115', '276', '308', '5', '449', '120', '247', '614', '677', '202', '10', '56', '533', '142', '500', '340', '670', '174', '42', '417', '24', '37', '25', '257', '389', '52', '14', '504', '110', '587', '619', '196', '559', '638', '20', '421', '46', '93', '284', '228', '448', '57', '78', '29', '475', '164', '591', '646', '253', '106', '121', '84', '480', '147', '280', '61', '221', '396', '89', '133', '116', '1', '507', '312', '74', '307', '452', '6', '248', '60', '117', '678', '529', '85', '201', '220', '366', '534', '102', '334', '28', '38', '561', '392', '70', '424', '192', '21', '137', '165', '33', '92', '229', '252', '197', '361', '65', '97', '665', '583', '285', '224', '650', '615', '9', '53', '169', '593', '141', '610', '420', '109', '256', '225', '339', '77', '193', '669', '476', '642', '637', '590', '679', '96', '393', '647', '173', '13', '41', '503', '134', '73', '105', '2', '508', '311', '558', '674', '530', '586', '618', '166', '32', '34', '148', '45', '161', '279', '64', '689', '17', '149', '584', '562', '176', '423', '191', '22', '44', '59', '118', '281', '27', '641', '71', '391', '12', '445', '54', '313', '611', '144', '49', '335', '86', '672', '172', '113', '681', '219', '419', '81', '230', '362', '451', '76', '7', '39', '649', '98', '616', '477', '367', '535', '103', '140', '621', '91', '66', '251', '668', '198', '108', '278', '223', '394', '306', '135', '563', '226', '3', '505', '80', '167', '35', '473', '675', '589', '162', '531', '680', '255', '648', '112', '617', '194', '145', '48', '557', '690', '63', '640', '18', '282', '95', '310', '50', '67', '199', '673', '16', '585', '502', '338', '643', '31', '336', '613', '11', '72', '175', '446', '612', '143', '43', '250', '231', '450', '99', '363', '556', '87', '203', '671', '688', '104', '368', '588', '40', '304', '26', '258', '390', '55', '114', '171', '139', '418', '23', '8', '75', '119', '58', '667', '478', '536', '82', '620', '447', '36', '168', '146', '30', '51', '190', '19', '422', '564', '305', '107', '4', '136', '506', '79', '195', '474', '664', '532', '94', '283', '395', '332', '528', '644', '47', '15', '163', '200', '68', '62', '277', '691', '501', '90', '111', '254', '227', '337', '122', '83', '309', '560', '639', '676', '222', '592', '364', '100']\n",
            "+-----+--------------------+--------------------+\n",
            "|label|            features|             indexed|\n",
            "+-----+--------------------+--------------------+\n",
            "|  0.0|(692,[127,128,129...|(692,[127,128,129...|\n",
            "|  1.0|(692,[158,159,160...|(692,[158,159,160...|\n",
            "|  1.0|(692,[124,125,126...|(692,[124,125,126...|\n",
            "|  1.0|(692,[152,153,154...|(692,[152,153,154...|\n",
            "|  1.0|(692,[151,152,153...|(692,[151,152,153...|\n",
            "|  0.0|(692,[129,130,131...|(692,[129,130,131...|\n",
            "|  1.0|(692,[158,159,160...|(692,[158,159,160...|\n",
            "|  1.0|(692,[99,100,101,...|(692,[99,100,101,...|\n",
            "|  0.0|(692,[154,155,156...|(692,[154,155,156...|\n",
            "|  0.0|(692,[127,128,129...|(692,[127,128,129...|\n",
            "|  1.0|(692,[154,155,156...|(692,[154,155,156...|\n",
            "|  0.0|(692,[153,154,155...|(692,[153,154,155...|\n",
            "|  0.0|(692,[151,152,153...|(692,[151,152,153...|\n",
            "|  1.0|(692,[129,130,131...|(692,[129,130,131...|\n",
            "|  0.0|(692,[154,155,156...|(692,[154,155,156...|\n",
            "|  1.0|(692,[150,151,152...|(692,[150,151,152...|\n",
            "|  0.0|(692,[124,125,126...|(692,[124,125,126...|\n",
            "|  0.0|(692,[152,153,154...|(692,[152,153,154...|\n",
            "|  1.0|(692,[97,98,99,12...|(692,[97,98,99,12...|\n",
            "|  1.0|(692,[124,125,126...|(692,[124,125,126...|\n",
            "+-----+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aKr141EnXU_"
      },
      "source": [
        "## Bucketizer\n",
        "\n",
        "Bucketizer transforms a column of continuous features to a column of feature buckets, where the buckets are specified by users\n",
        "\n",
        "[link](https://spark.apache.org/docs/2.4.7/ml-features.html#bucketizer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBaFKGYkvscq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1d97693-6452-4093-934e-8eacdb6edfbb"
      },
      "source": [
        "from pyspark.ml.feature import Bucketizer\n",
        "\n",
        "splits = [-float(\"inf\"), -0.5, 0.0, 0.5, float(\"inf\")]\n",
        "\n",
        "data = [\n",
        "    (-999.9,),\n",
        "    (-0.5,),\n",
        "    (-0.3,),\n",
        "    (-0.4,),\n",
        "    (-0.2,),\n",
        "    (0.0,),\n",
        "    (0.1,),\n",
        "    (0.2,),\n",
        "    (0.3,),\n",
        "    (999.9,),\n",
        "]\n",
        "dataFrame = spark.createDataFrame(data, [\"features\"])\n",
        "\n",
        "bucketizer = Bucketizer(\n",
        "    splits=splits, inputCol=\"features\", outputCol=\"bucketedFeatures\"\n",
        ")\n",
        "\n",
        "# Transform original data into its bucket index.\n",
        "bucketedData = bucketizer.transform(dataFrame)\n",
        "\n",
        "print(f\"Bucketizer output with {len(bucketizer.getSplits())-1} buckets\")\n",
        "bucketedData.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bucketizer output with 4 buckets\n",
            "+--------+----------------+\n",
            "|features|bucketedFeatures|\n",
            "+--------+----------------+\n",
            "|  -999.9|             0.0|\n",
            "|    -0.5|             1.0|\n",
            "|    -0.3|             1.0|\n",
            "|    -0.4|             1.0|\n",
            "|    -0.2|             1.0|\n",
            "|     0.0|             2.0|\n",
            "|     0.1|             2.0|\n",
            "|     0.2|             2.0|\n",
            "|     0.3|             2.0|\n",
            "|   999.9|             3.0|\n",
            "+--------+----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJMHqcKEvscq"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3ixMz5Qo0X9"
      },
      "source": [
        "## Prepare your Data for your ML algorithms  \n",
        "\n",
        "- label \n",
        "- Features "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AicWQYg9wHl9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4286500a-ccaa-40b6-e813-f53710f2ba28"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.linalg import Vectors\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# Prepare training data from a list of (label, features) tuples.\n",
        "training = spark.createDataFrame(\n",
        "    [\n",
        "        (1.0, Vectors.dense([0.0, 1.1, 0.1])),\n",
        "        (0.0, Vectors.dense([2.0, 1.0, -1.0])),\n",
        "        (0.0, Vectors.dense([2.0, 1.3, 1.0])),\n",
        "        (1.0, Vectors.dense([0.0, 1.2, -0.5])),\n",
        "    ],\n",
        "    [\"label\", \"features\"],\n",
        ")\n",
        "\n",
        "# Prepare data\n",
        "data = spark.createDataFrame(\n",
        "    [\n",
        "        (1.0, Vectors.dense([-1.0, 1.5, 1.3])),\n",
        "        (0.0, Vectors.dense([3.0, 2.0, -0.1])),\n",
        "        (1.0, Vectors.dense([0.0, 2.2, -0.0])),\n",
        "        (1.0, Vectors.dense([-1.5, 1.5, 1.9])),\n",
        "        (0.0, Vectors.dense([0.0, 0.0, -0.1])),\n",
        "        (1.0, Vectors.dense([0.0, 2.2, -1.5])),\n",
        "    ],\n",
        "    [\"label\", \"features\"],\n",
        ")\n",
        "\n",
        "data.show(10)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------------+\n",
            "|label|      features|\n",
            "+-----+--------------+\n",
            "|  1.0|[-1.0,1.5,1.3]|\n",
            "|  0.0|[3.0,2.0,-0.1]|\n",
            "|  1.0|[0.0,2.2,-0.0]|\n",
            "|  1.0|[-1.5,1.5,1.9]|\n",
            "|  0.0|[0.0,0.0,-0.1]|\n",
            "|  1.0|[0.0,2.2,-1.5]|\n",
            "+-----+--------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1xQ0B35rBXV"
      },
      "source": [
        "## Correlation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80ktIS_7wjZW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6d009c6-0b23-4c06-9924-f6c80ce451ab"
      },
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.stat import Correlation\n",
        "\n",
        "data = [\n",
        "    (Vectors.sparse(4, [(0, 100.0), (3, -2.0)]),),\n",
        "    (Vectors.dense([4.0, 5.0, 0.0, 3.0]),),\n",
        "    (Vectors.dense([6.0, 7.0, 0.0, 8.0]),),\n",
        "    (Vectors.sparse(4, [(0, 9.0), (3, 1.0)]),),\n",
        "]\n",
        "df = spark.createDataFrame(data, [\"features\"])\n",
        "\n",
        "# Pearson\n",
        "print(\"Pearson correlation matrix:\")\n",
        "r1 = Correlation.corr(df, \"features\")\n",
        "#r1.show()\n",
        "print(f\"{r1.first()[0]}\\n\")\n",
        "\n",
        "# Spearman\n",
        "df = df.cache()\n",
        "print(\"Spearman correlation matrix:\")\n",
        "r2 = Correlation.corr(df, \"features\", \"spearman\")\n",
        "#r2.show()\n",
        "print(f\"{r2.first()[0]}\\n\")\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pearson correlation matrix:\n",
            "DenseMatrix([[ 1.        , -0.58938206,         nan, -0.72490248],\n",
            "             [-0.58938206,  1.        ,         nan,  0.91359586],\n",
            "             [        nan,         nan,  1.        ,         nan],\n",
            "             [-0.72490248,  0.91359586,         nan,  1.        ]])\n",
            "\n",
            "Spearman correlation matrix:\n",
            "DenseMatrix([[ 1.        , -0.73786479,         nan, -0.8       ],\n",
            "             [-0.73786479,  1.        ,         nan,  0.9486833 ],\n",
            "             [        nan,         nan,  1.        ,         nan],\n",
            "             [-0.8       ,  0.9486833 ,         nan,  1.        ]])\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG0HCBpPwjZY"
      },
      "source": [
        "## Summarizer\n",
        "\n",
        "Spark provides vector column summary statistics for Dataframes through Summarizer. Available metrics are the column-wise max, min, mean, variance, and number of nonzeros, as well as the total count. \n",
        "\n",
        "This feature was newly added in Spark 2.4.0 \n",
        "\n",
        "\n",
        "### `ml.stat.Summarizer`\n",
        "API guide: https://spark.apache.org/docs/2.4.7/api/python/pyspark.ml.html#pyspark.ml.stat.Summarizer  \n",
        "Tools for vectorized statistics on MLlib Vectors. The methods in this package provide various statistics for `Vectors` contained inside `DataFrame`s. This class lets users pick the statistics they would like to extract for a given column.\n",
        "\n",
        "There are two ways to use this class, singular or multiple. Instructions below.\n",
        "\n",
        "#### 1. Computing singular metrics:\n",
        "- `mean(col, weightCol=None)`  \n",
        "coefficient-wise mean.\n",
        "- `variance(col, weightCol=None)`  \n",
        "coefficient-wise variance.\n",
        "- `count(col, weightCol=None)`  \n",
        "count of all vectors seen\n",
        "- `numNonZeros(col, weightCol=None)`  \n",
        "number of non-zeros for each coefficient\n",
        "- `max(col, weightCol=None)`  \n",
        "maximum for each coefficient\n",
        "- `min(col, weightCol=None)`  \n",
        "minimum for each coefficient\n",
        "- `normL1(col, weightCol=None)`  \n",
        "L1 norm of each coefficient (sum of the absolute values)\n",
        "- `normL2(col, weightCol=None)`  \n",
        "Euclidean norm for each coefficient\n",
        "    \n",
        "#### 2. Multiple metrics  \n",
        "To compute multiple metrics, first run `Summarizer.metrics` with the specific metrics that you want to compute.\n",
        "\n",
        "- `Summarizer.metrics(*metrics)`\n",
        "Given a list of metrics, provides a builder that computes metrics from a column.  \n",
        "Available metrics (same as singular metrics above): `mean`, `variance`, `count`, `numNonZeros`, `max`, `min`, `normL1`, `normL2`\n",
        "\n",
        "This returns an instance of the `SummaryBuilder` class. On this return instance of `SummaryBuilder` use the `.summary()` method.  \n",
        "```python\n",
        "SummaryBuilder.summary(\"featuresCol\", weightCol=None)\n",
        "```\n",
        "\n",
        "### Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5rhCvW5wjZa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f0bee17-5977-4ed5-bc71-436937ea091e"
      },
      "source": [
        "from pyspark.ml.stat import Summarizer\n",
        "from pyspark.ml.linalg import Vectors\n",
        "\n",
        "data = [\n",
        "    (1.0, Vectors.dense(1.0, 1.0, 1.0)),\n",
        "    (0.0, Vectors.dense(1.0, 2.0, 3.0)),\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(data, [\"weight\", \"features\"])\n",
        "\n",
        "# compute statistics for single metric \"mean\" with weight\n",
        "df.select(Summarizer.mean(df.features, df.weight)).show(truncate=False)\n",
        "\n",
        "# compute statistics for single metric \"mean\" without weight\n",
        "df.select(Summarizer.mean(df.features)).show(truncate=False)\n",
        "\n",
        "# create summarizer for multiple metrics \"mean\", \"count\", \"numNonZeros\"\n",
        "summarizer = Summarizer.metrics(\"mean\", \"count\", \"numNonZeros\")\n",
        "\n",
        "# compute statistics for multiple metrics with weight\n",
        "df.select(summarizer.summary(df.features, df.weight)).show(truncate=False)\n",
        "\n",
        "# compute statistics for multiple metrics without weight\n",
        "df.select(summarizer.summary(df.features)).show(truncate=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+\n",
            "|mean(features)|\n",
            "+--------------+\n",
            "|[1.0,1.0,1.0] |\n",
            "+--------------+\n",
            "\n",
            "+--------------+\n",
            "|mean(features)|\n",
            "+--------------+\n",
            "|[1.0,1.5,2.0] |\n",
            "+--------------+\n",
            "\n",
            "+-----------------------------------+\n",
            "|aggregate_metrics(features, weight)|\n",
            "+-----------------------------------+\n",
            "|[[1.0,1.0,1.0], 1, [1.0,1.0,1.0]]  |\n",
            "+-----------------------------------+\n",
            "\n",
            "+---------------------------------+\n",
            "|aggregate_metrics(features, 1.0) |\n",
            "+---------------------------------+\n",
            "|[[1.0,1.5,2.0], 2, [2.0,2.0,2.0]]|\n",
            "+---------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2ie5KqxpLxA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}