{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Copy of Spark_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmIDnTMWSJT5"
      },
      "source": [
        "# Setup Spark environment "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7-agJILRFIP",
        "outputId": "85ec35f4-5032-43b9-f16f-d40863a3ecf3"
      },
      "source": [
        "import time\n",
        "import os\n",
        "\n",
        "Start=time.time()\n",
        "# Download and install tools \n",
        "\n",
        "# Install Java\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Download and Install Spark\n",
        "!wget  -q http://apache.osuosl.org/spark/spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.7-bin-hadoop2.7.tgz\n",
        "\n",
        "# Install findspark\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set environment variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.7-bin-hadoop2.7\"\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "print(f\"\\nIt took {(time.time()-Start)} seconds to install all dependencies for spark to run on Google Colab. \\n\")\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "It took 39.47919535636902 seconds to install all dependencies for spark to run on Google Colab. \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZQaLgHDQ-9y"
      },
      "source": [
        "# All files present in the data/mllib folder\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agJzTnhzX_cL"
      },
      "source": [
        "- Spark ships with a good number of test data sets that can be used for all kinds of training and testing.\n",
        "\n",
        "- This data can be explored by browsing to the installation path of Spark and checking out the folder marked `data`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "zoThriwUQ-94",
        "outputId": "cb3ac54f-666b-4269-af9a-3de0f1351100"
      },
      "source": [
        "from pathlib import Path\n",
        "from IPython.display import HTML\n",
        "\n",
        "PATH = \"/content/spark-2.4.7-bin-hadoop2.7/data/mllib\"\n",
        "\n",
        "files = [str(x).replace(PATH + \"/\", \"\") for x in Path(PATH).glob(\"**/*\") if x.is_file()]\n",
        "files.sort()\n",
        "folders = [\n",
        "    f\"<font color='rgba(0, 0, 0, 87)' size='1'>{'/'.join(f.split('/')[:-1])}/</font>\"  # folder part\n",
        "    f\"{f.split('/')[-1]}\"  # file part\n",
        "    for f in files\n",
        "    if \"/\" in f\n",
        "]\n",
        "files = folders + [f for f in files if \"/\" not in f]\n",
        "\n",
        "HTML(\n",
        "    f\"<font face='courier' size='2'>\"\n",
        "    f\"<strong>All files present in the data/mllib folder:</strong><br />\"\n",
        "    f\"{''.join([f'<li>{str(f)}</li>' for f in files])}\"\n",
        "    f\"</font>\"\n",
        ")\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<font face='courier' size='2'><strong>All files present in the data/mllib folder:</strong><br /><li><font color='rgba(0, 0, 0, 87)' size='1'>als/</font>sample_movielens_ratings.txt</li><li><font color='rgba(0, 0, 0, 87)' size='1'>als/</font>test.data</li><li><font color='rgba(0, 0, 0, 87)' size='1'>images/</font>license.txt</li><li><font color='rgba(0, 0, 0, 87)' size='1'>images/origin/kittens/</font>29.5.a_b_EGDP022204.jpg</li><li><font color='rgba(0, 0, 0, 87)' size='1'>images/origin/kittens/</font>54893.jpg</li><li><font color='rgba(0, 0, 0, 87)' size='1'>images/origin/kittens/</font>DP153539.jpg</li><li><font color='rgba(0, 0, 0, 87)' size='1'>images/origin/kittens/</font>DP802813.jpg</li><li><font color='rgba(0, 0, 0, 87)' size='1'>images/origin/kittens/</font>not-image.txt</li><li><font color='rgba(0, 0, 0, 87)' size='1'>images/origin/</font>license.txt</li><li><font color='rgba(0, 0, 0, 87)' size='1'>images/origin/multi-channel/</font>BGRA.png</li><li><font color='rgba(0, 0, 0, 87)' size='1'>images/origin/multi-channel/</font>BGRA_alpha_60.png</li><li><font color='rgba(0, 0, 0, 87)' size='1'>images/origin/multi-channel/</font>chr30.4.184.jpg</li><li><font color='rgba(0, 0, 0, 87)' size='1'>images/origin/multi-channel/</font>grayscale.jpg</li><li><font color='rgba(0, 0, 0, 87)' size='1'>images/partitioned/cls=kittens/date=2018-01/</font>29.5.a_b_EGDP022204.jpg</li><li><font color='rgba(0, 0, 0, 87)' size='1'>images/partitioned/cls=kittens/date=2018-01/</font>not-image.txt</li><li><font color='rgba(0, 0, 0, 87)' size='1'>images/partitioned/cls=kittens/date=2018-02/</font>54893.jpg</li><li><font color='rgba(0, 0, 0, 87)' size='1'>images/partitioned/cls=kittens/date=2018-02/</font>DP153539.jpg</li><li><font color='rgba(0, 0, 0, 87)' size='1'>images/partitioned/cls=kittens/date=2018-02/</font>DP802813.jpg</li><li><font color='rgba(0, 0, 0, 87)' size='1'>images/partitioned/cls=multichannel/date=2018-01/</font>BGRA.png</li><li><font color='rgba(0, 0, 0, 87)' size='1'>images/partitioned/cls=multichannel/date=2018-01/</font>BGRA_alpha_60.png</li><li><font color='rgba(0, 0, 0, 87)' size='1'>images/partitioned/cls=multichannel/date=2018-02/</font>chr30.4.184.jpg</li><li><font color='rgba(0, 0, 0, 87)' size='1'>images/partitioned/cls=multichannel/date=2018-02/</font>grayscale.jpg</li><li><font color='rgba(0, 0, 0, 87)' size='1'>ridge-data/</font>lpsa.data</li><li>gmm_data.txt</li><li>iris_libsvm.txt</li><li>kmeans_data.txt</li><li>pagerank_data.txt</li><li>pic_data.txt</li><li>sample_binary_classification_data.txt</li><li>sample_fpgrowth.txt</li><li>sample_isotonic_regression_libsvm_data.txt</li><li>sample_kmeans_data.txt</li><li>sample_lda_data.txt</li><li>sample_lda_libsvm_data.txt</li><li>sample_libsvm_data.txt</li><li>sample_linear_regression_data.txt</li><li>sample_movielens_data.txt</li><li>sample_multiclass_classification_data.txt</li><li>sample_svm_data.txt</li><li>streaming_kmeans_data_test.txt</li></font>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCKFI1WnvHTq"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCijGq6LvqVQ"
      },
      "source": [
        "\n",
        "## Logistic regression classifier  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqLF_M3HuaDU",
        "outputId": "bfe17b53-1f5a-4336-8266-8e08126c9303"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "\n",
        "# Load training data\n",
        "PATH = \"/content/spark-2.4.7-bin-hadoop2.7/data/mllib/sample_libsvm_data.txt\"\n",
        "data = spark.read.format(\"libsvm\").load(PATH)\n",
        "\n",
        "\n",
        "# Split the data into training and test sets (30% held out for testing)\n",
        "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
        "\n",
        "logr = LogisticRegression()\n",
        "\n",
        "# Fit the model\n",
        "logrModel = logr.fit(trainingData)\n",
        "\n",
        "\n",
        "# Use model to predict Samples \n",
        "\n",
        "predictions_train = logrModel.transform(trainingData)\n",
        "\n",
        "predictions_train.select(\"prediction\", \"label\", \"features\").show(5)\n",
        "\n",
        "# Select (prediction, true label) and compute  accuracy\n",
        "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "acc= evaluator_acc.evaluate(predictions_train)\n",
        "\n",
        "print(f\"Accuracy [Training] = {100*acc}%\")\n",
        "\n",
        "# Make predictions.\n",
        "predictions = logrModel.transform(testData)\n",
        "\n",
        "# Select example rows to display.\n",
        "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
        "\n",
        "# Select (prediction, true label) and compute test accuracy\n",
        "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "acc = evaluator_acc.evaluate(predictions)\n",
        "print(f\"Accuracy [Testing] = {100*acc}%\")\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-----+--------------------+\n",
            "|prediction|label|            features|\n",
            "+----------+-----+--------------------+\n",
            "|       0.0|  0.0|(692,[95,96,97,12...|\n",
            "|       0.0|  0.0|(692,[100,101,102...|\n",
            "|       0.0|  0.0|(692,[121,122,123...|\n",
            "|       0.0|  0.0|(692,[122,123,124...|\n",
            "|       0.0|  0.0|(692,[123,124,125...|\n",
            "+----------+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Accuracy [Training] = 100.0%\n",
            "+----------+-----+--------------------+\n",
            "|prediction|label|            features|\n",
            "+----------+-----+--------------------+\n",
            "|       0.0|  0.0|(692,[98,99,100,1...|\n",
            "|       0.0|  0.0|(692,[122,123,148...|\n",
            "|       0.0|  0.0|(692,[124,125,126...|\n",
            "|       0.0|  0.0|(692,[124,125,126...|\n",
            "|       0.0|  0.0|(692,[126,127,128...|\n",
            "+----------+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Accuracy [Testing] = 100.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bONEBabSv2aL"
      },
      "source": [
        "## Decision Tree classifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aLMGsXbvnPG",
        "outputId": "66bc8240-1784-4ce2-adac-72ac54cb6fc7"
      },
      "source": [
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "\n",
        "# Load training data\n",
        "PATH = \"/content/spark-2.4.7-bin-hadoop2.7/data/mllib/sample_libsvm_data.txt\"\n",
        "data = spark.read.format(\"libsvm\").load(PATH)\n",
        "\n",
        "\n",
        "# Split the data into training and test sets (30% held out for testing)\n",
        "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
        "\n",
        "DT = DecisionTreeClassifier()\n",
        "\n",
        "# Fit the model\n",
        "DTClass = DT.fit(trainingData)\n",
        "\n",
        "\n",
        "# Use model to predict Samples \n",
        "\n",
        "predictions_train = DTClass.transform(trainingData)\n",
        "\n",
        "predictions_train.select(\"prediction\", \"label\", \"features\").show(5)\n",
        "\n",
        "# Select (prediction, true label) and compute  accuracy\n",
        "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "acc= evaluator_acc.evaluate(predictions_train)\n",
        "\n",
        "print(f\"Accuracy [Training] = {100*acc}%\")\n",
        "\n",
        "# Make predictions.\n",
        "predictions = DTClass.transform(testData)\n",
        "\n",
        "# Select example rows to display.\n",
        "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
        "\n",
        "# Select (prediction, true label) and compute test accuracy\n",
        "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "acc = evaluator_acc.evaluate(predictions)\n",
        "print(f\"Accuracy [Testing] = {100*acc}%\")\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-----+--------------------+\n",
            "|prediction|label|            features|\n",
            "+----------+-----+--------------------+\n",
            "|       0.0|  0.0|(692,[95,96,97,12...|\n",
            "|       0.0|  0.0|(692,[98,99,100,1...|\n",
            "|       0.0|  0.0|(692,[121,122,123...|\n",
            "|       0.0|  0.0|(692,[122,123,124...|\n",
            "|       0.0|  0.0|(692,[123,124,125...|\n",
            "+----------+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Accuracy [Training] = 100.0%\n",
            "+----------+-----+--------------------+\n",
            "|prediction|label|            features|\n",
            "+----------+-----+--------------------+\n",
            "|       0.0|  0.0|(692,[100,101,102...|\n",
            "|       0.0|  0.0|(692,[122,123,148...|\n",
            "|       0.0|  0.0|(692,[123,124,125...|\n",
            "|       0.0|  0.0|(692,[124,125,126...|\n",
            "|       0.0|  0.0|(692,[124,125,126...|\n",
            "+----------+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Accuracy [Testing] = 100.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X6LDz07wI3g"
      },
      "source": [
        "## Random Forest classifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYnatqgswPw1",
        "outputId": "d42b6e75-bd2f-4fea-e5fc-4ff8fc30d048"
      },
      "source": [
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "\n",
        "# Load training data\n",
        "PATH = \"/content/spark-2.4.7-bin-hadoop2.7/data/mllib/sample_libsvm_data.txt\"\n",
        "data = spark.read.format(\"libsvm\").load(PATH)\n",
        "\n",
        "\n",
        "# Split the data into training and test sets (30% held out for testing)\n",
        "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
        "\n",
        "RF = RandomForestClassifier()\n",
        "\n",
        "# Fit the model\n",
        "RFClass = RF.fit(trainingData)\n",
        "\n",
        "\n",
        "# Use model to predict Samples \n",
        "\n",
        "predictions_train = RFClass.transform(trainingData)\n",
        "\n",
        "predictions_train.select(\"prediction\", \"label\", \"features\").show(5)\n",
        "\n",
        "# Select (prediction, true label) and compute  accuracy\n",
        "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "acc= evaluator_acc.evaluate(predictions_train)\n",
        "\n",
        "print(f\"Accuracy [Training] = {100*acc}%\")\n",
        "\n",
        "# Make predictions.\n",
        "predictions = RFClass.transform(testData)\n",
        "\n",
        "# Select example rows to display.\n",
        "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
        "\n",
        "# Select (prediction, true label) and compute test accuracy\n",
        "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "acc = evaluator_acc.evaluate(predictions)\n",
        "print(f\"Accuracy [Testing] = {100*acc}%\")\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-----+--------------------+\n",
            "|prediction|label|            features|\n",
            "+----------+-----+--------------------+\n",
            "|       0.0|  0.0|(692,[95,96,97,12...|\n",
            "|       0.0|  0.0|(692,[121,122,123...|\n",
            "|       0.0|  0.0|(692,[122,123,124...|\n",
            "|       0.0|  0.0|(692,[122,123,148...|\n",
            "|       0.0|  0.0|(692,[123,124,125...|\n",
            "+----------+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Accuracy [Training] = 100.0%\n",
            "+----------+-----+--------------------+\n",
            "|prediction|label|            features|\n",
            "+----------+-----+--------------------+\n",
            "|       0.0|  0.0|(692,[98,99,100,1...|\n",
            "|       0.0|  0.0|(692,[100,101,102...|\n",
            "|       0.0|  0.0|(692,[123,124,125...|\n",
            "|       0.0|  0.0|(692,[123,124,125...|\n",
            "|       0.0|  0.0|(692,[124,125,126...|\n",
            "+----------+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Accuracy [Testing] = 100.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LrhNuSUwYVl",
        "outputId": "abbbfe2f-2abc-4750-e28c-ffcfd94ebb0a"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "from pyspark.ml.classification import GBTClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "\n",
        "# Load training data\n",
        "PATH = \"/content/spark-2.4.7-bin-hadoop2.7/data/mllib/sample_libsvm_data.txt\"\n",
        "data = spark.read.format(\"libsvm\").load(PATH)\n",
        "\n",
        "\n",
        "# Split the data into training and test sets (30% held out for testing)\n",
        "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
        "\n",
        "GB = GBTClassifier()\n",
        "\n",
        "# Fit the model\n",
        "GBClass = GB.fit(trainingData)\n",
        "\n",
        "\n",
        "# Use model to predict Samples \n",
        "\n",
        "predictions_train = GBClass.transform(trainingData)\n",
        "\n",
        "predictions_train.select(\"prediction\", \"label\", \"features\").show(5)\n",
        "\n",
        "# Select (prediction, true label) and compute  accuracy\n",
        "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "acc= evaluator_acc.evaluate(predictions_train)\n",
        "\n",
        "print(f\"Accuracy [Training] = {100*acc}%\")\n",
        "\n",
        "# Make predictions.\n",
        "predictions = GBClass.transform(testData)\n",
        "\n",
        "# Select example rows to display.\n",
        "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
        "\n",
        "# Select (prediction, true label) and compute test accuracy\n",
        "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "acc = evaluator_acc.evaluate(predictions)\n",
        "print(f\"Accuracy [Testing] = {100*acc}%\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-----+--------------------+\n",
            "|prediction|label|            features|\n",
            "+----------+-----+--------------------+\n",
            "|       0.0|  0.0|(692,[95,96,97,12...|\n",
            "|       0.0|  0.0|(692,[98,99,100,1...|\n",
            "|       0.0|  0.0|(692,[121,122,123...|\n",
            "|       0.0|  0.0|(692,[123,124,125...|\n",
            "|       0.0|  0.0|(692,[123,124,125...|\n",
            "+----------+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Accuracy [Training] = 100.0%\n",
            "+----------+-----+--------------------+\n",
            "|prediction|label|            features|\n",
            "+----------+-----+--------------------+\n",
            "|       0.0|  0.0|(692,[100,101,102...|\n",
            "|       0.0|  0.0|(692,[122,123,124...|\n",
            "|       0.0|  0.0|(692,[122,123,148...|\n",
            "|       0.0|  0.0|(692,[124,125,126...|\n",
            "|       0.0|  0.0|(692,[126,127,128...|\n",
            "+----------+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Accuracy [Testing] = 96.96969696969697%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8RDGTNOskGf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}